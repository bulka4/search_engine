{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f3fb4c2-6cc7-48f1-95da-16865ee4db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.utils import pad_sequences\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae5c1c7f-32ca-4db4-a20f-c24764eb1fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(string: str, \n",
    "               punctuations = r'''!()-[]{};:'\"\\,<>./?@#$%^&*_~''',\n",
    "               stop_words = stopwords.words('english'),\n",
    "               # porter = PorterStemmer()\n",
    "               wnl = WordNetLemmatizer()\n",
    "              ):\n",
    "    \"\"\"\n",
    "    A method to clean text. It removes punctuations, stop words, applies lemmatization.\n",
    "    \"\"\"\n",
    "    # Removing the punctuations\n",
    "    for x in string.lower(): \n",
    "        if x in punctuations: \n",
    "            string = string.replace(x, \"\") \n",
    "\n",
    "    # Converting the text to lower\n",
    "    string = string.lower()\n",
    "\n",
    "    # Removing stop words\n",
    "    string = ' '.join([word for word in string.split() if word not in stop_words])\n",
    "\n",
    "    # stemming/lemmatizing words. That means changing word to its basic format, for example\n",
    "    # words 'fishing', 'fished', 'fischer' will be changed into a word 'fisch'\n",
    "    # lemmatization should be better because stemming changes words too much, for example\n",
    "    # business is changed into busi\n",
    "    # string = ' '.join([porter.stem(word) for word in string.split()])\n",
    "    string = ' '.join([wnl.lemmatize(word, pos = \"v\") for word in string.split()])\n",
    "\n",
    "    # Cleaning the whitespaces\n",
    "    string = re.sub(r'\\s+', ' ', string).strip()\n",
    "\n",
    "    return string\n",
    "\n",
    "def create_training_data(sentences_file,\n",
    "                         model_folder,\n",
    "                         word_vec_dim,\n",
    "                         embed_file_path,\n",
    "                         max_sen_len = None,\n",
    "                         create_embedding_file = False\n",
    "                        ):\n",
    "    \"\"\"\n",
    "    Creating a training and testing datasets x_train and x_test, and embedding matrix.\n",
    "    \n",
    "    Argument sentences_file is a path to the file with sentences.\n",
    "    \n",
    "    Argument model_folder is a name of a folder where we will save tokenizer which will be needed after model is\n",
    "    trained to encode new sentences.\n",
    "    \n",
    "    Argument word_vec_dim indicates a length of a vector embeddings.\n",
    "    \n",
    "    Argument embed_file_path is a path to a file with vector embeddings assigned to words, like 'glove.840B.300d.txt'.\n",
    "    \n",
    "    Argument create_embedding_file indicates if we want to create a new, smaller file with word embeddings from\n",
    "    'glove.840B.300d.txt' such that it contains only words which are present in sentences_file.\n",
    "    \"\"\"\n",
    "    sentences_tables = pd.read_excel(sentences_file).values\n",
    "    random.shuffle(sentences_tables)\n",
    "    clean_sentences = np.array([clean_text(sentence) for sentence in sentences_tables[:, 0]])\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(clean_sentences)\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(clean_sentences)\n",
    "    if max_sen_len == None:\n",
    "        max_sen_len = np.max([len(seq) for seq in sequences])\n",
    "    x = pad_sequences(sequences, maxlen = max_sen_len)\n",
    "\n",
    "    x_train, x_test = train_test_split(x, test_size = 0.2)\n",
    "    \n",
    "    embed_matrix = create_embedding_matrix(\n",
    "        tokenizer = tokenizer,\n",
    "        model_folder = model_folder,\n",
    "        word_vec_dim = word_vec_dim,\n",
    "        embed_file_path = embed_file_path\n",
    "    )\n",
    "    \n",
    "    with open(os.path.join(model_folder, 'tokenizer.json'), 'w') as file:\n",
    "        json.dump(tokenizer.to_json(), file)\n",
    "        \n",
    "    x_train.to_csv(os.path.join(model_folder, 'x_train.csv'))\n",
    "    x_test.to_csv(os.path.join(model_folder, 'x_test.csv'))\n",
    "    embed_matrix.to_csv(os.path.join(model_folder, 'embed_matrix.csv'))\n",
    "    \n",
    "    if create_embedding_file:\n",
    "        create_embedding_file(tokenizer = tokenizer)\n",
    "        \n",
    "    return x_train, x_test, embed_matrix\n",
    "\n",
    "\n",
    "def get_coefs(word, *arr): \n",
    "    return word, list(np.asarray(arr, dtype='float'))\n",
    "\n",
    "\n",
    "def create_embedding_file(tokenizer,\n",
    "                          embed_file_src = r'model\\glove.840B.300d.txt', \n",
    "                          embed_file_trg = r'model\\model_embeddings.txt'\n",
    "                         ):\n",
    "    \"\"\"\n",
    "    This function will create an embedding file called embed_file_trg which will contain only those words \n",
    "    from embed_file_src which are present in the training dataset (tokenizer.word_index).\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings = dict(get_coefs(*o.split(\" \")) for o in open(embed_file_src, errors = 'ignore'))\n",
    "    with open(embed_file_trg, 'w') as file:\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            word_vector = embeddings[word]\n",
    "            line = ' '.join(np.concatenate([[word], word_vector]))\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "\n",
    "def create_embedding_matrix(tokenizer,\n",
    "                            model_folder,\n",
    "                            word_vec_dim,\n",
    "                            embed_file_path,\n",
    "                           ):\n",
    "    \"\"\"\n",
    "    A function to create an embedding matrix. This is a matrix where each row is a vector representing a word.\n",
    "    To create that matrix we use a word embedding file which path is equal to embedding_file_path.\n",
    "    embedding_matrix[row_number] is a vector representation for a word = list(tokenizer.word_index.keys())[row_number - 1]\n",
    "    First row of embedding_matrix are zeros. This matrix is needed to train a model.\n",
    "    \"\"\"\n",
    "    embeddings = dict(get_coefs(*o.split(\" \")) for o in open(embed_file_path, errors = 'ignore'))\n",
    "\n",
    "    # embedding_matrix[row_number] is a vector representation of a word = self.tokenizer.word_index.keys()[row_number - 1]\n",
    "    # first row in embedding_matrix is 0\n",
    "    embedding_matrix = np.zeros((len(tokenizer.word_counts) + 1, word_vec_dim))\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index > len(tokenizer.word_counts):\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                embedding_matrix[index] = embeddings[word]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a6c030-6b64-4d53-9cdf-18ae47d5b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_file = r'data\\sentences_tables.xlsx'\n",
    "model_folder = 'model'\n",
    "word_vec_dim = 300\n",
    "embed_file_path = r'model\\model_embeddings.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa21b414-1a9d-4045-b551-9416b28cf16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, embed_matrix = create_training_data(\n",
    "    sentences_file = sentences_file,\n",
    "    model_folder = model_folder,\n",
    "    word_vec_dim = word_vec_dim,\n",
    "    embed_file_path = embed_file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "703325ad-5693-45fb-8ca5-0632a439fcfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  6,  7, 14],\n",
       "       [ 0,  0,  0, ..., 15,  1,  4],\n",
       "       [ 0,  0,  0, ..., 27, 12,  1],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 19,  8,  1],\n",
       "       [ 0,  0,  0, ..., 17,  2,  5],\n",
       "       [ 0,  0,  0, ..., 13,  6,  7]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a69efdd-4542-4dfc-8cb3-d65237cdf61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [-0.50318 ,  0.27905 , -0.045497, ...,  0.4781  ,  0.13005 ,\n",
       "        -0.014399],\n",
       "       [-0.89423 ,  0.39636 ,  0.64359 , ..., -0.15076 ,  0.06987 ,\n",
       "         0.041258],\n",
       "       ...,\n",
       "       [-0.39054 , -0.55117 , -0.073466, ...,  0.34569 ,  0.30918 ,\n",
       "        -0.32873 ],\n",
       "       [ 0.049725, -0.48829 , -0.11179 , ...,  0.033829, -0.068756,\n",
       "        -0.43567 ],\n",
       "       [ 0.37492 , -0.052425, -0.60094 , ..., -0.36104 , -0.065253,\n",
       "        -0.1206  ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd8b29fc-9891-4abb-8213-07ab482b117c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# check if some word doesnt have vector embeddings assigned\n",
    "for i, row in enumerate(embed_matrix):\n",
    "    if (row == np.zeros(300)).all():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8854e78-9e2f-4fde-973c-209d545335c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('employee', 1)\n",
      "('cost', 2)\n",
      "('user', 3)\n",
      "('office', 4)\n",
      "('business', 5)\n",
      "('unit', 6)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(tokenizer.word_index.items()):\n",
    "    print(item)\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "130632c9-bbf4-4a09-a7e1-e8c153935bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    def __init__(self,\n",
    "                 embedding_dim,\n",
    "                 lstm_out_size,\n",
    "                 batch_size,\n",
    "                 embed_matrix\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.lstm_out_size = lstm_out_size\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = layers.Embedding(\n",
    "            input_dim = embed_matrix.shape[0],\n",
    "            output_dim = embedding_dim,\n",
    "            embeddings_initializer = tf.keras.initializers.Constant(embed_matrix),\n",
    "            trainable = False\n",
    "        )\n",
    "        self.lstm = layers.LSTM(\n",
    "            units = self.lstm_out_size,\n",
    "            return_sequences = True,\n",
    "            return_state = True\n",
    "        )\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, x, state_h = None, state_c = None):\n",
    "        # x.shape = (batch_size, max_sen_len)\n",
    "        # x is a series of numbers which represent words\n",
    "        # state_h.shape = (batch_size, lstm_out_size)\n",
    "        \n",
    "        if state_h == None or state_c == None:\n",
    "            state_h, state_c = self.initialize_hidden_state()\n",
    "        \n",
    "        # make sure that the types are correct\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        state_h = tf.cast(state_h, tf.float32)\n",
    "        state_c = tf.cast(state_c, tf.float32)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        # x.shape after embedding = (batch_size, max_sen_len, embedding_dim)\n",
    "        # output.shape = (batch_size, max_sen_len, lstm_out_size)\n",
    "        # state_h.shape = (batch_size, lstm_out_size)\n",
    "        output, state_h, state_c = self.lstm(x, initial_state = [state_h, state_c])\n",
    "        return output, state_h, state_c\n",
    "    \n",
    "    @tf.function\n",
    "    def initialize_hidden_state(self):\n",
    "        state_h = tf.zeros((self.batch_size, self.lstm_out_size))\n",
    "        state_c = tf.zeros((self.batch_size, self.lstm_out_size))\n",
    "        return state_h, state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e07b1daa-cfc1-4cfe-85a6-a58ce5120f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(embedding_dim = 300,\n",
    "                 lstm_out_size = 10,\n",
    "                 batch_size = 2,\n",
    "                 embed_matrix = embed_matrix\n",
    "                 )\n",
    "\n",
    "x = np.array([[1, 2], [1, 2]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    output, state_h, state_c = encoder(x)\n",
    "    \n",
    "variables = encoder.trainable_variables\n",
    "gradients = tape.gradient(output, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "936a4350-b1cc-44bb-8e82-74be79bd3b83",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(300, 40), dtype=float32, numpy=\n",
       " array([[ 3.91362980e-02,  1.78501666e-01, -6.65536746e-02, ...,\n",
       "          2.27576867e-03,  3.06596979e-03, -5.52950427e-03],\n",
       "        [-2.44583692e-02, -1.00564852e-01,  4.86165360e-02, ...,\n",
       "          4.39209789e-02,  3.47434767e-02,  3.46905664e-02],\n",
       "        [ 7.62790767e-03,  1.84747055e-02, -2.33989414e-02, ...,\n",
       "         -6.68730587e-02, -5.38272634e-02, -4.74490821e-02],\n",
       "        ...,\n",
       "        [-4.10167016e-02, -1.71791986e-01,  7.95203224e-02, ...,\n",
       "          6.06815591e-02,  4.77755107e-02,  4.92389351e-02],\n",
       "        [-6.89753098e-03, -4.42978255e-02,  3.52535956e-03, ...,\n",
       "         -5.33669665e-02, -4.33627591e-02, -3.55112329e-02],\n",
       "        [-7.87226111e-03, -2.61273235e-05,  3.63165438e-02, ...,\n",
       "          1.47570401e-01,  1.19062632e-01,  1.03082106e-01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 40), dtype=float32, numpy=\n",
       " array([[ 6.16146077e-04,  3.51791561e-04, -2.61891261e-03,\n",
       "         -8.49191158e-04, -2.83790007e-03, -7.85931305e-04,\n",
       "          2.48138164e-03, -7.55050592e-03, -5.71352849e-03,\n",
       "         -7.98935350e-03,  5.70962846e-04,  3.45674856e-03,\n",
       "         -1.05071394e-03, -7.94795749e-04, -9.95087554e-04,\n",
       "         -1.64881392e-04,  2.02416768e-03, -1.22586254e-03,\n",
       "         -1.25461491e-03, -1.28804415e-03, -2.40219980e-02,\n",
       "         -2.27704532e-02, -1.61680132e-02, -2.66883299e-02,\n",
       "         -1.08878417e-02, -1.61510017e-02, -2.79187560e-02,\n",
       "         -1.04743456e-02, -9.64249391e-03, -1.07615450e-02,\n",
       "          2.45235395e-03,  5.10128867e-03, -3.97462305e-03,\n",
       "         -2.96703260e-03, -6.38126861e-03, -1.25083548e-03,\n",
       "          6.03190670e-03, -1.01070870e-02, -8.15218035e-03,\n",
       "         -7.07404548e-03],\n",
       "        [ 2.82713096e-03,  1.61416398e-03, -1.20166447e-02,\n",
       "         -3.89643735e-03, -1.30214496e-02, -3.60617531e-03,\n",
       "          1.13855973e-02, -3.46448161e-02, -2.62160115e-02,\n",
       "         -3.66584323e-02,  2.61981180e-03,  1.58609804e-02,\n",
       "         -4.82110679e-03, -3.64684896e-03, -4.56586992e-03,\n",
       "         -7.56543421e-04,  9.28771123e-03, -5.62476041e-03,\n",
       "         -5.75668784e-03, -5.91007480e-03, -1.10222779e-01,\n",
       "         -1.04480177e-01, -7.41854757e-02, -1.22457005e-01,\n",
       "         -4.99578826e-02, -7.41074160e-02, -1.28102705e-01,\n",
       "         -4.80605960e-02, -4.42437194e-02, -4.93783839e-02,\n",
       "          1.12524061e-02,  2.34068055e-02, -1.82372015e-02,\n",
       "         -1.36139616e-02, -2.92798784e-02, -5.73934615e-03,\n",
       "          2.76768636e-02, -4.63754609e-02, -3.74055468e-02,\n",
       "         -3.24586220e-02],\n",
       "        [-1.04392448e-03, -5.96033700e-04,  4.43717325e-03,\n",
       "          1.43876823e-03,  4.80819959e-03,  1.33158837e-03,\n",
       "         -4.20415727e-03,  1.27926767e-02,  9.68032144e-03,\n",
       "          1.35362092e-02, -9.67371394e-04, -5.85670257e-03,\n",
       "          1.78020447e-03,  1.34660723e-03,  1.68595777e-03,\n",
       "          2.79355387e-04, -3.42950854e-03,  2.07695551e-03,\n",
       "          2.12566997e-03,  2.18230835e-03,  4.07000072e-02,\n",
       "          3.85795422e-02,  2.73931548e-02,  4.52175252e-02,\n",
       "          1.84470620e-02,  2.73643304e-02,  4.73022126e-02,\n",
       "          1.77464839e-02,  1.63370930e-02,  1.82330795e-02,\n",
       "         -4.15497646e-03, -8.64301529e-03,  6.73412764e-03,\n",
       "          5.02698636e-03,  1.08116614e-02,  2.11926643e-03,\n",
       "         -1.02197444e-02,  1.71242431e-02,  1.38120819e-02,\n",
       "          1.19854202e-02],\n",
       "        [-7.02842022e-04, -4.01291036e-04,  2.98741134e-03,\n",
       "          9.68678098e-04,  3.23721184e-03,  8.96517187e-04,\n",
       "         -2.83052912e-03,  8.61291308e-03,  6.51746104e-03,\n",
       "          9.11351014e-03, -6.51301176e-04, -3.94313643e-03,\n",
       "          1.19855662e-03,  9.06628964e-04,  1.13510317e-03,\n",
       "          1.88081322e-04, -2.30898196e-03,  1.39834976e-03,\n",
       "          1.43114780e-03,  1.46928069e-03,  2.74020564e-02,\n",
       "          2.59744097e-02,  1.84429642e-02,  3.04435603e-02,\n",
       "          1.24198347e-02,  1.84235573e-02,  3.18471156e-02,\n",
       "          1.19481580e-02,  1.09992586e-02,  1.22757675e-02,\n",
       "         -2.79741688e-03, -5.81907481e-03,  4.53387946e-03,\n",
       "          3.38451425e-03,  7.27915671e-03,  1.42683659e-03,\n",
       "         -6.88063726e-03,  1.15292231e-02,  9.29924753e-03,\n",
       "          8.06941185e-03],\n",
       "        [-5.27013850e-04, -3.00901098e-04,  2.24005827e-03,\n",
       "          7.26346392e-04,  2.42736680e-03,  6.72237773e-04,\n",
       "         -2.12242268e-03,  6.45824289e-03,  4.88700438e-03,\n",
       "          6.83360687e-03, -4.88366815e-04, -2.95669213e-03,\n",
       "          8.98716738e-04,  6.79819903e-04,  8.51137273e-04,\n",
       "          1.41029494e-04, -1.73134974e-03,  1.04852812e-03,\n",
       "          1.07312121e-03,  1.10171444e-03,  2.05469541e-02,\n",
       "          1.94764584e-02,  1.38291344e-02,  2.28275731e-02,\n",
       "          9.31279641e-03,  1.38145825e-02,  2.38800030e-02,\n",
       "          8.95911735e-03,  8.24760273e-03,  9.20477044e-03,\n",
       "         -2.09759432e-03, -4.36333194e-03,  3.39965057e-03,\n",
       "          2.53781886e-03,  5.45814866e-03,  1.06988847e-03,\n",
       "         -5.15932590e-03,  8.64498690e-03,  6.97287824e-03,\n",
       "          6.05070777e-03],\n",
       "        [-2.72740057e-04, -1.55722242e-04,  1.15927437e-03,\n",
       "          3.75898584e-04,  1.25621026e-03,  3.47896304e-04,\n",
       "         -1.09839567e-03,  3.34226806e-03,  2.52912100e-03,\n",
       "          3.53652635e-03, -2.52739468e-04, -1.53014658e-03,\n",
       "          4.65103629e-04,  3.51820199e-04,  4.40480333e-04,\n",
       "          7.29855456e-05, -8.96007637e-04,  5.42633992e-04,\n",
       "          5.55361388e-04,  5.70158998e-04,  1.06334537e-02,\n",
       "          1.00794518e-02,  7.15684984e-03,  1.18137188e-02,\n",
       "          4.81955614e-03,  7.14931870e-03,  1.23583730e-02,\n",
       "          4.63652005e-03,  4.26829699e-03,  4.76365024e-03,\n",
       "         -1.08554633e-03, -2.25811033e-03,  1.75938627e-03,\n",
       "          1.31337135e-03,  2.82469951e-03,  5.53688384e-04,\n",
       "         -2.67005293e-03,  4.47395118e-03,  3.60860210e-03,\n",
       "          3.13136075e-03],\n",
       "        [ 1.72759534e-03,  9.86378873e-04, -7.34309806e-03,\n",
       "         -2.38102395e-03, -7.95711111e-03, -2.20365147e-03,\n",
       "          6.95747882e-03, -2.11706590e-02, -1.60200074e-02,\n",
       "         -2.24011317e-02,  1.60090718e-03,  9.69228335e-03,\n",
       "         -2.94606830e-03, -2.22850638e-03, -2.79009901e-03,\n",
       "         -4.62306460e-04,  5.67550864e-03, -3.43716284e-03,\n",
       "         -3.51778069e-03, -3.61151202e-03, -6.73546270e-02,\n",
       "         -6.38454556e-02, -4.53330539e-02, -7.48306811e-02,\n",
       "         -3.05281244e-02, -4.52853516e-02, -7.82806426e-02,\n",
       "         -2.93687340e-02, -2.70363279e-02, -3.01740039e-02,\n",
       "          6.87608868e-03,  1.43033648e-02, -1.11443382e-02,\n",
       "         -8.31918232e-03, -1.78922657e-02, -3.50718363e-03,\n",
       "          1.69127006e-02, -2.83389874e-02, -2.28576753e-02,\n",
       "         -1.98347252e-02],\n",
       "        [-1.14537845e-03, -6.53959287e-04,  4.86840028e-03,\n",
       "          1.57859514e-03,  5.27548511e-03,  1.46099890e-03,\n",
       "         -4.61273873e-03,  1.40359346e-02,  1.06211044e-02,\n",
       "          1.48517266e-02, -1.06138550e-03, -6.42588688e-03,\n",
       "          1.95321394e-03,  1.47747737e-03,  1.84980780e-03,\n",
       "          3.06504546e-04, -3.76280560e-03,  2.27880455e-03,\n",
       "          2.33225338e-03,  2.39439635e-03,  4.46554422e-02,\n",
       "          4.23288979e-02,  3.00553627e-02,  4.96119969e-02,\n",
       "          2.02398412e-02,  3.00237369e-02,  5.18992804e-02,\n",
       "          1.94711778e-02,  1.79248154e-02,  2.00050622e-02,\n",
       "         -4.55877790e-03, -9.48298816e-03,  7.38858478e-03,\n",
       "          5.51553443e-03,  1.18623935e-02,  2.32522772e-03,\n",
       "         -1.12129515e-02,  1.87884644e-02,  1.51544111e-02,\n",
       "          1.31502245e-02],\n",
       "        [-7.20181852e-04, -4.11191286e-04,  3.06111365e-03,\n",
       "          9.92576359e-04,  3.31707695e-03,  9.18635167e-04,\n",
       "         -2.90036085e-03,  8.82540271e-03,  6.67825295e-03,\n",
       "          9.33834910e-03, -6.67369401e-04, -4.04041773e-03,\n",
       "          1.22812612e-03,  9.28996364e-04,  1.16310723e-03,\n",
       "          1.92721476e-04, -2.36594654e-03,  1.43284840e-03,\n",
       "          1.46645552e-03,  1.50552928e-03,  2.80780904e-02,\n",
       "          2.66152248e-02,  1.88979693e-02,  3.11946310e-02,\n",
       "          1.27262445e-02,  1.88780837e-02,  3.26328129e-02,\n",
       "          1.22429300e-02,  1.12706209e-02,  1.25786224e-02,\n",
       "         -2.86643184e-03, -5.96263679e-03,  4.64573503e-03,\n",
       "          3.46801337e-03,  7.45874038e-03,  1.46203802e-03,\n",
       "         -7.05038942e-03,  1.18136602e-02,  9.52866860e-03,\n",
       "          8.26849230e-03],\n",
       "        [-8.66642687e-04, -4.94813838e-04,  3.68364179e-03,\n",
       "          1.19443319e-03,  3.99165927e-03,  1.10545475e-03,\n",
       "         -3.49019724e-03,  1.06201936e-02,  8.03638622e-03,\n",
       "          1.12374574e-02, -8.03090050e-04, -4.86210315e-03,\n",
       "          1.47788587e-03,  1.11792306e-03,  1.39964430e-03,\n",
       "          2.31914571e-04, -2.84710107e-03,  1.72424177e-03,\n",
       "          1.76468352e-03,  1.81170355e-03,  3.37882340e-02,\n",
       "          3.20278704e-02,  2.27411836e-02,  3.75385769e-02,\n",
       "          1.53143369e-02,  2.27172542e-02,  3.92692350e-02,\n",
       "          1.47327324e-02,  1.35626886e-02,  1.51366936e-02,\n",
       "         -3.44936806e-03, -7.17523787e-03,  5.59052173e-03,\n",
       "          4.17329138e-03,  8.97559896e-03,  1.75936753e-03,\n",
       "         -8.48420244e-03,  1.42161632e-02,  1.14664808e-02,\n",
       "          9.95002687e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(40,), dtype=float32, numpy=\n",
       " array([-0.09601873, -0.3651618 ,  0.20979817,  0.06284291,  0.14610083,\n",
       "         0.06006461, -0.27875867,  0.25046563,  0.20975704,  0.27237064,\n",
       "        -0.01280924, -0.07755028,  0.0235722 ,  0.01783081,  0.02232425,\n",
       "         0.00369902, -0.0454111 ,  0.02750156,  0.0281466 ,  0.02889657,\n",
       "         1.3454621 ,  0.84417355,  1.2938945 ,  1.8149537 ,  0.5718073 ,\n",
       "         0.83917165,  1.4247936 ,  1.44938   ,  0.6097311 ,  1.200451  ,\n",
       "        -0.09839188, -0.265769  ,  0.15980157,  0.11609915,  0.20449454,\n",
       "         0.03828417, -0.2543427 ,  0.29469424,  0.23524943,  0.22041392],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "447a3847-162c-40c5-91aa-4387850d7f7d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 10), dtype=float32, numpy=\n",
       "array([[[-0.04457429, -0.20452513,  0.07552136,  0.0508462 ,\n",
       "          0.03812613,  0.01973103, -0.12498064,  0.08286092,\n",
       "          0.05210062,  0.06269614],\n",
       "        [-0.05648873, -0.13043042,  0.1044731 ,  0.06710292,\n",
       "          0.10755109,  0.02488116, -0.18320872,  0.2810727 ,\n",
       "          0.16890085,  0.2183119 ]],\n",
       "\n",
       "       [[-0.04457429, -0.20452513,  0.07552136,  0.0508462 ,\n",
       "          0.03812613,  0.01973103, -0.12498064,  0.08286092,\n",
       "          0.05210062,  0.06269614],\n",
       "        [-0.05648873, -0.13043042,  0.1044731 ,  0.06710292,\n",
       "          0.10755109,  0.02488116, -0.18320872,  0.2810727 ,\n",
       "          0.16890085,  0.2183119 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e586409-6d87-463c-90dd-40135c565e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1 like in Jonathan Hui pdf\n",
    "class Bahdau_attention(layers.Layer):\n",
    "    def __init__(self, units = 10):\n",
    "        super().__init__()\n",
    "        self.W1 = layers.Dense(units)\n",
    "        self.W2 = layers.Dense(units)\n",
    "        self.V = layers.Dense(1)\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, decoder_hidden, encoder_hidden):\n",
    "        # decoder_hidden.shape = (batch_size, hidden_size)\n",
    "        # decoder_hidden_time_axis.shape = (batch_size, 1, hidden_size)\n",
    "        decoder_hidden_time_axis = tf.expand_dims(decoder_hidden, 1)\n",
    "        \n",
    "        # encoder_hidden.shape = (batch_size, max_sen_len, hidden_size)\n",
    "        # argument for tanh shape = (batch_size, max_sen_len, hidden_size)\n",
    "        # score.shape = (batch_size, max_sen_len, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(decoder_hidden_time_axis) + self.W2(encoder_hidden)))\n",
    "        \n",
    "        # attention_weights.shape = (batch_size, max_sen_len, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis = 1)\n",
    "        \n",
    "        # context_vector.shape = (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * encoder_hidden\n",
    "        context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
    "        \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69eb4b57-421e-4ad8-91fa-c445ee520f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2, like in attention explanation pdf\n",
    "class Bahdau_attention(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(1)\n",
    "       \n",
    "    @tf.function\n",
    "    def call(self, decoder_state_h, encoder_states_h):\n",
    "        # decoder_state_h.shape = (batch_size, dec_state_size)\n",
    "        # encoder_states_h.shape = (batch_size, max_sen_len, enc_state_size)\n",
    "        \n",
    "        # make sure that the dtypes are correct\n",
    "        decoder_state_h = tf.cast(decoder_state_h, tf.float32)\n",
    "        encoder_states_h = tf.cast(encoder_states_h, tf.float32)\n",
    "        \n",
    "        # encoder_states_h_flattened.shape = (batch_size * max_sen_len, enc_state_size)\n",
    "        # encoder_states_h_flattened = tf.reshape(encoder_states_h, [-1, tf.shape(encoder_states_h)[2]])\n",
    "        encoder_states_h_flattened = tf.reshape(\n",
    "            encoder_states_h, [\n",
    "                tf.shape(encoder_states_h)[0] * tf.shape(encoder_states_h)[1], \n",
    "                tf.shape(encoder_states_h)[2]\n",
    "            ]\n",
    "        )\n",
    "        batch_size = tf.shape(encoder_states_h)[0]\n",
    "        max_sen_len = tf.shape(encoder_states_h)[1]\n",
    "        enc_state_size = tf.shape(encoder_states_h)[2]\n",
    "        \n",
    "        context_vector = tf.TensorArray(dtype = tf.float32, size = 0, dynamic_size = True, clear_after_read = False)\n",
    "        for b in tf.range(batch_size):\n",
    "            alpha = e = tf.TensorArray(dtype = tf.float32, size = 0, dynamic_size = True, clear_after_read = False)\n",
    "            for j in tf.range(max_sen_len):\n",
    "                # x.shape = (dec_state_size + enc_state_size)\n",
    "                x = tf.concat([decoder_state_h[b], encoder_states_h_flattened[b * max_sen_len + j]], 0)\n",
    "                # x.shape = (1, dec_state_size + enc_state_size)\n",
    "                x = tf.expand_dims(x, 0)\n",
    "                e = e.write(j, tf.math.exp(self.dense(x))[0])\n",
    "\n",
    "            e_sum = tf.math.reduce_sum(e.stack())\n",
    "            for j in tf.range(max_sen_len):\n",
    "                alpha = alpha.write(j, tf.math.divide(e.read(j), e_sum))\n",
    "\n",
    "            Sum = tf.TensorArray(dtype = tf.float32, size = 0, dynamic_size = True, clear_after_read = False)\n",
    "            for j in tf.range(max_sen_len):\n",
    "                Sum = Sum.write(j, alpha.read(j) * encoder_states_h_flattened[b * max_sen_len + j])\n",
    "\n",
    "            # context_vector_b is a context vector for 1 sample from batch\n",
    "            context_vector_b = tf.math.reduce_sum(Sum.stack(), axis = 0)\n",
    "            # context_vector.shape = (batch_size, enc_state_size)\n",
    "            context_vector = context_vector.write(b, context_vector_b)\n",
    "        \n",
    "        return context_vector.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4abc0a9f-5f9e-4c5f-8ee0-d29769dafa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.run_functions_eagerly(True)\n",
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a9ec3a1b-a11a-496d-8cb8-95960056ab17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention = Bahdau_attention()\n",
    "decoder_state_h = tf.constant([[1,2], [4,5]])\n",
    "encoder_states_h = tf.constant([[[1,2,3], [4,5,3]], [[1,2,3], [4,5,3]]])\n",
    "encoder_states_h_flattened = tf.reshape(encoder_states_h, [tf.shape(encoder_states_h)[0] * tf.shape(encoder_states_h)[1], tf.shape(encoder_states_h)[2]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    context_vector = attention(decoder_state_h, encoder_states_h)\n",
    "    \n",
    "variables = attention.trainable_variables\n",
    "gradients = tape.gradient(context_vector, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "63891f45-e849-4848-80a9-da55a4b71126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3.5908003, 4.5908003, 3.       ],\n",
       "       [3.5908003, 4.5908003, 3.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d5307f81-c5f4-4cf3-b0d4-6a4c2bf50631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       " array([[-1.1920929e-06],\n",
       "        [-2.1457672e-06],\n",
       "        [ 4.2406158e+00],\n",
       "        [ 4.2406149e+00],\n",
       "        [-3.0994415e-06]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-1.013279e-06], dtype=float32)>]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15a6c0cc-731a-475c-bc69-bea3475e4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, lstm_out_size, embed_matrix):\n",
    "        super().__init__()\n",
    "        self.lstm_out_size = lstm_out_size\n",
    "        self.embedding = layers.Embedding(\n",
    "            input_dim = embed_matrix.shape[0],\n",
    "            output_dim = embedding_dim,\n",
    "            embeddings_initializer = tf.keras.initializers.Constant(embed_matrix),\n",
    "            trainable = False\n",
    "        )\n",
    "        self.lstm = layers.LSTM(\n",
    "            units = self.lstm_out_size,\n",
    "            # return_sequences = True,\n",
    "            return_state = True\n",
    "        )\n",
    "        self.dense = layers.Dense(vocab_size)\n",
    "        self.attention = Bahdau_attention()\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, x, decoder_state_h, decoder_state_c, encoder_states_h):\n",
    "        # x.shape = (batch_size, 1)\n",
    "        # x is a single number for each batch representing a single word\n",
    "        # encoder_states_h.shape = (batch_size, max_sen_len, enc_state_size)\n",
    "        # decoder_state_h.shape = (batch_size, lstm_out_size)\n",
    "        \n",
    "        # make sure that the types are correct\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        decoder_state_h = tf.cast(decoder_state_h, tf.float32)\n",
    "        decoder_state_c = tf.cast(decoder_state_c, tf.float32)\n",
    "        encoder_states_h = tf.cast(encoder_states_h, tf.float32)\n",
    "        \n",
    "        # context_vector.shape = (batch_size, enc_state_size)\n",
    "        context_vector = self.attention(decoder_state_h, encoder_states_h)\n",
    "        # shape of output of embedding layer = (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        # x.shape after concatenation = (batch_size, 1, enc_state_size + embedding_dim)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis = 2)\n",
    "        \n",
    "        output, state_h, state_c = self.lstm(x, initial_state = [decoder_state_h, decoder_state_c])\n",
    "        \n",
    "        # output.shape = (batch_size, vocab_size)\n",
    "        output = self.dense(output)\n",
    "        \n",
    "        return output, state_h, state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0bfb23f3-bb93-4967-9b92-8bdf3247ab4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_size = 100, \n",
    "                  embedding_dim = 300, \n",
    "                  lstm_out_size = 20, \n",
    "                  embed_matrix = embed_matrix\n",
    "                 )\n",
    "\n",
    "x = tf.constant([[1], [2]])\n",
    "decoder_state_h = tf.constant([[i for i in range(20)], [i for i in range(20)]])\n",
    "decoder_state_c = tf.constant([[i for i in range(20)], [i for i in range(20)]])\n",
    "encoder_states_h = tf.constant([[[i for i in range(15)], [i for i in range(15)]], [[i for i in range(15)], [i for i in range(15)]]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    output, state_h, state_c = decoder(x, decoder_state_h, decoder_state_c, encoder_states_h)\n",
    "    \n",
    "variables = decoder.trainable_variables\n",
    "gradients = tape.gradient(output, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "38e7a82a-d985-433a-8a7b-0ee95bc9447e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 100), dtype=float32, numpy=\n",
       "array([[ 0.15162158, -0.2666756 , -0.08206277,  0.71664655,  0.15774032,\n",
       "        -0.26463896, -0.02485025, -0.16136312,  0.32311562,  0.31768876,\n",
       "        -0.38081762, -0.59177405, -0.35685304, -0.5143362 ,  0.37344497,\n",
       "        -0.51701427,  0.24112938,  0.3559965 , -0.23429905, -0.93242985,\n",
       "         0.14618877,  0.46973363, -0.7733953 ,  0.16248974,  0.03708994,\n",
       "        -0.05201417,  0.17080984,  0.08245593, -0.53828734,  0.5289846 ,\n",
       "        -0.7155414 , -0.2436806 ,  0.09993283, -0.64873123, -0.38315713,\n",
       "         0.4200229 ,  0.02848363, -0.07834591,  0.26870382,  0.37282366,\n",
       "        -0.86660933,  0.79235697, -0.47088167,  0.46041852,  0.12979311,\n",
       "         0.30807993,  0.3242702 , -0.0882818 , -0.298767  ,  0.15185268,\n",
       "         0.4537142 ,  0.4380744 ,  0.50783145,  0.2062283 ,  0.416616  ,\n",
       "        -0.24646498, -0.66551596,  0.10805789, -0.4846673 ,  0.11572916,\n",
       "         0.79025435,  0.10220787,  0.6163452 , -0.22814785, -0.5057447 ,\n",
       "         0.39544344, -0.06590679,  0.60514987, -0.00322172,  0.26729006,\n",
       "        -0.32098946, -0.11905575,  0.18295452,  0.28115597, -0.18187518,\n",
       "        -0.9423108 , -0.671106  , -0.38054192,  0.41401356, -0.31121212,\n",
       "         0.09302792,  0.02328775,  0.20752177,  0.45681006,  0.407726  ,\n",
       "        -0.48006344, -0.257822  ,  0.02856378, -0.14446467, -0.2501529 ,\n",
       "         0.31287432,  0.3248075 , -0.39628854, -0.30306733,  0.23548001,\n",
       "         0.09679663, -0.15450694,  0.5000636 , -0.04544456, -0.136026  ],\n",
       "       [ 0.14962938, -0.25731224, -0.1020506 ,  0.74165434,  0.16988227,\n",
       "        -0.25353545, -0.00930303, -0.18302968,  0.3293348 ,  0.33174652,\n",
       "        -0.40506244, -0.6096351 , -0.3950976 , -0.51407075,  0.40101132,\n",
       "        -0.53554595,  0.26527983,  0.34992194, -0.26417896, -0.9675321 ,\n",
       "         0.1488972 ,  0.47112727, -0.75738275,  0.17284009,  0.0447695 ,\n",
       "        -0.04068142,  0.172411  ,  0.10267399, -0.5499263 ,  0.5376295 ,\n",
       "        -0.748915  , -0.25476432,  0.0794469 , -0.6706539 , -0.3563583 ,\n",
       "         0.43546838,  0.03883401, -0.03957553,  0.2520967 ,  0.3544025 ,\n",
       "        -0.89587873,  0.81048834, -0.5096285 ,  0.479815  ,  0.14078659,\n",
       "         0.2999275 ,  0.3286984 , -0.09203713, -0.2861164 ,  0.14929047,\n",
       "         0.4844275 ,  0.43933004,  0.49119318,  0.19093968,  0.41867816,\n",
       "        -0.26108307, -0.6747335 ,  0.12904064, -0.50364935,  0.11115403,\n",
       "         0.78541887,  0.12439601,  0.6429752 , -0.23661476, -0.5237884 ,\n",
       "         0.39356777, -0.06530368,  0.6376973 ,  0.00318795,  0.26436985,\n",
       "        -0.33688334, -0.13508376,  0.19329348,  0.2740103 , -0.21423192,\n",
       "        -0.9375808 , -0.7042506 , -0.39134783,  0.4334551 , -0.33300954,\n",
       "         0.08642653,  0.02045148,  0.19888389,  0.46990553,  0.42168614,\n",
       "        -0.5161682 , -0.27263558,  0.02933484, -0.12576477, -0.27693444,\n",
       "         0.3377708 ,  0.2977826 , -0.39529914, -0.29846144,  0.22236711,\n",
       "         0.09808898, -0.15875454,  0.5058714 , -0.05592252, -0.1391761 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "df33af93-876e-474b-bedb-cbd64497f3ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(315, 80), dtype=float32, numpy=\n",
       " array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 2.05591097e-02,  5.87581750e-03,  4.36880291e-02, ...,\n",
       "         -5.95262408e-01, -2.95585115e-03, -2.01966166e-01],\n",
       "        [ 4.11182195e-02,  1.17516350e-02,  8.73760581e-02, ...,\n",
       "         -1.19052482e+00, -5.91170229e-03, -4.03932333e-01],\n",
       "        ...,\n",
       "        [-1.43110575e-02,  1.94085098e-03,  1.16645843e-02, ...,\n",
       "         -1.73727512e-01, -9.20270628e-04, -6.59215897e-02],\n",
       "        [-2.49217115e-02, -2.28512537e-04, -4.86101629e-03, ...,\n",
       "          4.93213274e-02,  1.79062117e-04,  8.75781570e-03],\n",
       "        [ 4.53935117e-02,  1.55893841e-03,  1.68263167e-02, ...,\n",
       "         -2.01263383e-01, -8.90372845e-04, -5.50800711e-02]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 80), dtype=float32, numpy=\n",
       " array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.0559110e-02,  5.8758175e-03,  4.3688029e-02, ...,\n",
       "         -5.9526241e-01, -2.9558511e-03, -2.0196617e-01],\n",
       "        [ 4.1118219e-02,  1.1751635e-02,  8.7376058e-02, ...,\n",
       "         -1.1905248e+00, -5.9117023e-03, -4.0393233e-01],\n",
       "        ...,\n",
       "        [ 3.4950486e-01,  9.9888898e-02,  7.4269652e-01, ...,\n",
       "         -1.0119461e+01, -5.0249469e-02, -3.4334247e+00],\n",
       "        [ 3.7006390e-01,  1.0576472e-01,  7.8638458e-01, ...,\n",
       "         -1.0714724e+01, -5.3205319e-02, -3.6353910e+00],\n",
       "        [ 3.9062309e-01,  1.1164053e-01,  8.3007258e-01, ...,\n",
       "         -1.1309986e+01, -5.6161173e-02, -3.8373570e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(80,), dtype=float32, numpy=\n",
       " array([ 2.05591097e-02,  5.87581750e-03,  4.36880291e-02,  6.54117612e-04,\n",
       "        -1.54203153e-05, -3.36056382e-06, -2.19798267e-07, -6.86364743e-08,\n",
       "         2.84002596e-07,  0.00000000e+00,  0.00000000e+00, -4.70721570e-04,\n",
       "         0.00000000e+00,  0.00000000e+00,  3.42125550e-09,  0.00000000e+00,\n",
       "         0.00000000e+00,  8.29843993e-05, -8.79508880e-05,  1.03225615e-08,\n",
       "         0.00000000e+00, -2.61173695e-01, -7.71053433e-02, -1.55263394e-02,\n",
       "        -1.73119770e-04, -8.13165784e-08, -1.96773181e-06, -2.39068899e-12,\n",
       "         5.97915860e-05,  0.00000000e+00,  0.00000000e+00, -1.22766485e-02,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.08334723e-06,  0.00000000e+00,\n",
       "         0.00000000e+00, -2.85898596e-02, -3.59257869e-03, -2.23458272e-07,\n",
       "         1.19763470e+00,  0.00000000e+00, -2.73926416e-04, -4.10720066e-04,\n",
       "        -1.03427315e-04, -9.01743291e-10,  0.00000000e+00, -8.73996964e-09,\n",
       "         5.43746959e-09,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -3.75132259e-10,  0.00000000e+00,\n",
       "         0.00000000e+00, -7.02071568e-10, -8.19780456e-04, -3.00826808e-09,\n",
       "         9.67675122e-04,  3.04572191e-02, -5.28654382e-02,  5.60756191e-04,\n",
       "        -6.53695911e-02, -1.41193241e-01, -7.66144076e-04, -2.51190364e-01,\n",
       "         6.08611626e-05,  2.02129632e-02, -2.35756829e-01, -1.41495094e-01,\n",
       "         7.13929594e-01, -3.59928571e-02, -1.07512195e-02,  6.21161453e-05,\n",
       "        -5.65255154e-03, -5.95262408e-01, -2.95585115e-03, -2.01966166e-01],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 100), dtype=float32, numpy=\n",
       " array([[ 0.06191017,  0.06191017,  0.06191017, ...,  0.06191017,\n",
       "          0.06191017,  0.06191017],\n",
       "        [-1.2220323 , -1.2220323 , -1.2220323 , ..., -1.2220323 ,\n",
       "         -1.2220323 , -1.2220323 ],\n",
       "        [ 0.18544804,  0.18544804,  0.18544804, ...,  0.18544804,\n",
       "          0.18544804,  0.18544804],\n",
       "        ...,\n",
       "        [ 1.298124  ,  1.298124  ,  1.298124  , ...,  1.298124  ,\n",
       "          1.298124  ,  1.298124  ],\n",
       "        [ 0.00187013,  0.00187013,  0.00187013, ...,  0.00187013,\n",
       "          0.00187013,  0.00187013],\n",
       "        [ 0.23752296,  0.23752296,  0.23752296, ...,  0.23752296,\n",
       "          0.23752296,  0.23752296]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       " array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(35, 1), dtype=float32, numpy=\n",
       " array([[0.00000000e+00],\n",
       "        [7.10375447e-09],\n",
       "        [1.42075089e-08],\n",
       "        [2.13112639e-08],\n",
       "        [2.84150179e-08],\n",
       "        [3.55187737e-08],\n",
       "        [4.26225277e-08],\n",
       "        [4.97262818e-08],\n",
       "        [5.68300358e-08],\n",
       "        [6.39337898e-08],\n",
       "        [7.10375474e-08],\n",
       "        [7.81412979e-08],\n",
       "        [8.52450555e-08],\n",
       "        [9.23488059e-08],\n",
       "        [9.94525635e-08],\n",
       "        [1.06556314e-07],\n",
       "        [1.13660072e-07],\n",
       "        [1.20763829e-07],\n",
       "        [1.27867580e-07],\n",
       "        [1.34971330e-07],\n",
       "        [0.00000000e+00],\n",
       "        [7.10375447e-09],\n",
       "        [1.42075089e-08],\n",
       "        [2.13112639e-08],\n",
       "        [2.84150179e-08],\n",
       "        [3.55187737e-08],\n",
       "        [4.26225277e-08],\n",
       "        [4.97262818e-08],\n",
       "        [5.68300358e-08],\n",
       "        [6.39337898e-08],\n",
       "        [7.10375474e-08],\n",
       "        [7.81412979e-08],\n",
       "        [8.52450555e-08],\n",
       "        [9.23488059e-08],\n",
       "        [9.94525635e-08]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([7.1037545e-09], dtype=float32)>]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "53ffc42e-fa8e-4ca6-956a-948ae38af438",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, \n",
    "               targ, \n",
    "               batch_size, \n",
    "               encoder, \n",
    "               decoder, \n",
    "               loss_function, \n",
    "               optimizer):\n",
    "    # inp.shape = targ.shape (batch_size, max_sen_len)\n",
    "    # enc_state_h.shape = (batch_size, enc_state_size)\n",
    "    \n",
    "    # make sure that the types are correct\n",
    "    inp = tf.cast(inp, tf.float32)\n",
    "    targ = tf.cast(targ, tf.float32)\n",
    "    \n",
    "    batch_loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # enc_output.shape = (batch_size, max_sen_len, enc_state_size)\n",
    "        # enc_state_h.shape = (batch_size, enc_state_size)\n",
    "        # enc_output, enc_state_h, enc_state_c = encoder(inp, enc_state_h, enc_state_c)\n",
    "        enc_output, enc_state_h, enc_state_c = encoder(inp)\n",
    "        dec_state_h = enc_state_h\n",
    "        dec_state_c = enc_state_c\n",
    "        \n",
    "        # dec_input.shape = (batch_size, 1)\n",
    "        dec_input = tf.expand_dims([0] * batch_size, 1)\n",
    "        \n",
    "        for t in range(targ.shape[1]):\n",
    "            prediction, dec_state_h, dec_state_c, = decoder(dec_input, dec_state_h, dec_state_c, enc_output)\n",
    "            # real value passed to loss_function needs to have shape (batch_size).\n",
    "            # It is a number representing a word from tokenizer.word_index. Real value = 0\n",
    "            # means that there was no word\n",
    "            batch_loss += loss_function(targ[:, t], prediction)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "            \n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(batch_loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3bd15e-6e38-4b08-92b2-530b10f6742e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555bc3a1-4872-4ca2-8ca7-f6e510dbdaa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4194725f-0785-46aa-96ea-9a53437540aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16035f6f-2d3d-43bd-8f41-174494e45259",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction = 'none')\n",
    "\n",
    "@tf.function\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype = loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a8ddff7-2151-45af-9547-df2a605e46cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.0108437e-04, 2.3841855e-07], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real = tf.expand_dims(x_train[:2, 0], 1)\n",
    "# pred = tf.expand_dims(x_train[:2, 0], 1)\n",
    "\n",
    "real = tf.constant([2, 0])\n",
    "pred = tf.constant([[0.0001, 0.00, 0.99], [1, 0, 0]])\n",
    "\n",
    "real = tf.cast(real, tf.float32)\n",
    "pred = tf.cast(pred, tf.float32)\n",
    "\n",
    "loss_object(real, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "423aca49-8c11-4305-bb06-80e0091323dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 20\n",
    "embedding_dim = 300\n",
    "\n",
    "inp = tf.constant(x_train)\n",
    "targ = tf.constant(x_train)\n",
    "\n",
    "decoder = Decoder(vocab_size = len(tokenizer.word_index.keys()) + 1,\n",
    "                  embedding_dim = embedding_dim,\n",
    "                  lstm_out_size = 100,\n",
    "                  embed_matrix = embed_matrix\n",
    "                 )\n",
    "\n",
    "encoder = Encoder(embedding_dim = embedding_dim,\n",
    "                 lstm_out_size = 100,\n",
    "                 batch_size = batch_size,\n",
    "                 embed_matrix = embed_matrix\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "48974688-4e2c-4b76-b5ea-b065ea4adc39",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number: 0, Loss: 2.809325933456421, Time per batch: 14.651074647903442\n",
      "Batch number: 1, Loss: 2.3995823860168457, Time per batch: 7.627819180488586\n",
      "Batch number: 2, Loss: 1.65554940700531, Time per batch: 5.285693724950154\n",
      "Batch number: 3, Loss: 1.7393203973770142, Time per batch: 4.116266667842865\n",
      "Batch number: 4, Loss: 1.6695903539657593, Time per batch: 3.4108400344848633\n",
      "Batch number: 5, Loss: 1.410011887550354, Time per batch: 2.9619738260904946\n",
      "Batch number: 6, Loss: 1.2773363590240479, Time per batch: 2.653951951435634\n",
      "Batch number: 7, Loss: 1.5331032276153564, Time per batch: 2.4294706284999847\n",
      "Batch number: 8, Loss: 1.2173337936401367, Time per batch: 2.2571023570166693\n",
      "Batch number: 9, Loss: 1.4510911703109741, Time per batch: 2.118311882019043\n",
      "Batch number: 10, Loss: 1.3761066198349, Time per batch: 2.007483720779419\n",
      "Batch number: 11, Loss: 1.3919532299041748, Time per batch: 1.9165438612302144\n",
      "Batch number: 12, Loss: 1.5510022640228271, Time per batch: 1.8359561883486235\n",
      "Batch number: 13, Loss: 1.142643928527832, Time per batch: 1.7689326320375716\n",
      "Batch number: 14, Loss: 1.1568653583526611, Time per batch: 1.712102731068929\n",
      "Batch number: 15, Loss: 1.4507606029510498, Time per batch: 1.660421371459961\n",
      "Batch number: 16, Loss: 1.4725298881530762, Time per batch: 1.6166633157169117\n",
      "Batch number: 17, Loss: 1.1476835012435913, Time per batch: 1.5769019789165921\n",
      "Batch number: 18, Loss: 1.3024498224258423, Time per batch: 1.5404530324433978\n",
      "Batch number: 19, Loss: 1.1571553945541382, Time per batch: 1.5083810567855835\n",
      "Batch number: 20, Loss: 1.274988055229187, Time per batch: 1.4800734519958496\n",
      "Batch number: 21, Loss: 1.173478364944458, Time per batch: 1.4544961885972456\n",
      "Batch number: 22, Loss: 1.1513862609863281, Time per batch: 1.4317668520885964\n",
      "Batch number: 23, Loss: 1.3987969160079956, Time per batch: 1.4096204042434692\n",
      "Batch number: 24, Loss: 1.7301784753799438, Time per batch: 1.3892680263519288\n",
      "Batch number: 25, Loss: 1.125253677368164, Time per batch: 1.3710663043535674\n",
      "Batch number: 26, Loss: 1.2986829280853271, Time per batch: 1.3547077355561432\n",
      "Batch number: 27, Loss: 1.6073312759399414, Time per batch: 1.3385037183761597\n",
      "Batch number: 28, Loss: 1.4865343570709229, Time per batch: 1.3236806310456375\n",
      "Batch number: 29, Loss: 1.6031156778335571, Time per batch: 1.3101104895273845\n",
      "Batch number: 30, Loss: 1.166068434715271, Time per batch: 1.2978000025595389\n",
      "Batch number: 31, Loss: 1.384772777557373, Time per batch: 1.2862935438752174\n",
      "Epoch: 1, Loss: 1.4597493410110474, Time per epoch: 41.16139340400696\n",
      "\n",
      "Batch number: 0, Loss: 1.4818811416625977, Time per batch: 0.9170126914978027\n",
      "Batch number: 1, Loss: 1.2972900867462158, Time per batch: 0.9244718551635742\n",
      "Batch number: 2, Loss: 1.1260031461715698, Time per batch: 0.9171770413716634\n",
      "Batch number: 3, Loss: 1.2230522632598877, Time per batch: 0.9251324534416199\n",
      "Batch number: 4, Loss: 1.1237376928329468, Time per batch: 0.9271750926971436\n",
      "Batch number: 5, Loss: 1.130398154258728, Time per batch: 0.9256117741266886\n",
      "Batch number: 6, Loss: 1.1682069301605225, Time per batch: 0.9290219715663365\n",
      "Batch number: 7, Loss: 1.2453407049179077, Time per batch: 0.9306021928787231\n",
      "Batch number: 8, Loss: 1.0732537508010864, Time per batch: 0.9341163900163438\n",
      "Batch number: 9, Loss: 1.2302169799804688, Time per batch: 0.9349624872207641\n",
      "Batch number: 10, Loss: 1.1638399362564087, Time per batch: 0.9364418116482821\n",
      "Batch number: 11, Loss: 1.250975489616394, Time per batch: 0.9400192300478617\n",
      "Batch number: 12, Loss: 1.3105566501617432, Time per batch: 0.9383610395284799\n",
      "Batch number: 13, Loss: 0.8967892527580261, Time per batch: 0.9368877410888672\n",
      "Epoch: 2, Loss: 1.1943957805633545, Time per epoch: 13.11642837524414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    stime = time.time()\n",
    "    total_loss = 0\n",
    "    for batch_number in range(len(inp) // batch_size):\n",
    "        inp_batch = inp[batch_number * batch_size : (batch_number + 1) * batch_size, :]\n",
    "        targ_batch = targ[batch_number * batch_size : (batch_number + 1) * batch_size, :]\n",
    "        \n",
    "        batch_loss = train_step(inp = inp_batch,\n",
    "                               targ = targ_batch,\n",
    "                               batch_size = batch_size,\n",
    "                               encoder = encoder,\n",
    "                               decoder = decoder,\n",
    "                               loss_function = loss_function,\n",
    "                               optimizer = optimizer\n",
    "                              )\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        print(f'Batch number: {batch_number}, Loss: {batch_loss / batch_size}, Time per batch: {(time.time() - stime) / (batch_number + 1)}')\n",
    "        if batch_loss / batch_size < 0.9:\n",
    "            break\n",
    "        \n",
    "    print(f'Epoch: {epoch + 1}, Loss: {total_loss / ((batch_number + 1) * batch_size)}, Time per epoch: {time.time() - stime}\\n')\n",
    "    if batch_loss / batch_size < 0.9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e01287fe-3046-471e-8839-c24375ec2207",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_21_layer_call_fn, lstm_cell_21_layer_call_and_return_conditional_losses, lstm_cell_21_layer_call_fn, lstm_cell_21_layer_call_and_return_conditional_losses, lstm_cell_21_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/encoder\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/encoder\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000187D3F83A48> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "encoder.save('model/encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f96b89c0-8f1e-48f0-8757-63827446b636",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses, dense_15_layer_call_fn, dense_15_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/decoder\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/decoder\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001878DBE25C8> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "decoder.save('model/decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a728ecf-d048-41f6-8b72-b4ffe7ea68b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564852cf-572d-4a31-9ffd-f480e106454d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09355e38-8ca7-4fa8-8773-c9ed04c2ea47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e150430-f367-490d-a742-60edff8d2af3",
   "metadata": {},
   "source": [
    "## model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1babf107-ce99-44d3-9207-feea1ca3a5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "encoder = load_model('model/encoder')\n",
    "decoder = load_model('model/decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4dd52fee-2373-4e4e-b70c-bd1a2ead6e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['employee', 'user', 'cost', 'office', 'business', 'unit', 'center', 'hierarchy', 'productivity', 'type', 'work', 'date', 'region', 'sub', 'timesheet', 'empower', 'email', 'join', 'name', 'activity', 'translate', 'department', 'perform', 'word', 'manager', 'code', 'measure', 'job', 'title', 'operation', 'country', 'currency', 'adress', 'city', 'language', 'helix', 'id', 'group', 'freelancer', 'vendor', 'status', 'client', 'mother', 'tongue', 'capacity'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42a6ebb4-7ca0-4123-ac02-d45b971fa2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return np.sqrt(np.sum((x - y) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b197d08d-abde-460c-a2ab-65a1208dce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.array([\n",
    "    'freelancer department', 'vendor office', 'office region', 'office business unit', 'manager name', 'user name',\n",
    "    'mother tongue', 'mother language', 'operation type', 'work type'\n",
    "])\n",
    "\n",
    "differences = pd.DataFrame()\n",
    "for sentence1 in sentences:\n",
    "    for sentence2 in np.delete(sentences, np.where(sentences == sentence1)):\n",
    "        sequences = tokenizer.texts_to_sequences([sentence1, sentence2])\n",
    "        x = pad_sequences(sequences, maxlen = 20)\n",
    "\n",
    "        for i in range(20 - x.shape[0]):\n",
    "            x = np.concatenate((x, np.zeros((1, 20))))\n",
    "\n",
    "        encoded_x = encoder(x)[0]\n",
    "        new_row = pd.DataFrame([[sentence1, sentence2, rmse(encoded_x[0].numpy(), encoded_x[1].numpy())]])\n",
    "        differences = pd.concat((differences, new_row))\n",
    "        \n",
    "differences.columns = ['sentence1', 'sentence2', 'difference']\n",
    "differences = differences.sort_values(by = 'difference')\n",
    "differences.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "3774963a-afc0-461e-b9af-4f0ec03d40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b32b75ec-a7a2-4e79-9cab-ca9fb36a55b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>operation type</td>\n",
       "      <td>user name</td>\n",
       "      <td>1.951066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>user name</td>\n",
       "      <td>operation type</td>\n",
       "      <td>1.951066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mother language</td>\n",
       "      <td>operation type</td>\n",
       "      <td>1.980350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>operation type</td>\n",
       "      <td>mother language</td>\n",
       "      <td>1.980350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>operation type</td>\n",
       "      <td>manager name</td>\n",
       "      <td>2.036666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>manager name</td>\n",
       "      <td>operation type</td>\n",
       "      <td>2.036666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>mother language</td>\n",
       "      <td>vendor office</td>\n",
       "      <td>2.051085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>vendor office</td>\n",
       "      <td>mother language</td>\n",
       "      <td>2.051085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>office region</td>\n",
       "      <td>manager name</td>\n",
       "      <td>2.058947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>manager name</td>\n",
       "      <td>office region</td>\n",
       "      <td>2.058947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>mother tongue</td>\n",
       "      <td>office region</td>\n",
       "      <td>2.079474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>office region</td>\n",
       "      <td>mother tongue</td>\n",
       "      <td>2.079474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>user name</td>\n",
       "      <td>freelancer department</td>\n",
       "      <td>2.113164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>freelancer department</td>\n",
       "      <td>user name</td>\n",
       "      <td>2.113164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>operation type</td>\n",
       "      <td>freelancer department</td>\n",
       "      <td>2.117957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>freelancer department</td>\n",
       "      <td>operation type</td>\n",
       "      <td>2.117957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>vendor office</td>\n",
       "      <td>office business unit</td>\n",
       "      <td>2.121174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>office business unit</td>\n",
       "      <td>vendor office</td>\n",
       "      <td>2.121174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>mother language</td>\n",
       "      <td>manager name</td>\n",
       "      <td>2.213384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>manager name</td>\n",
       "      <td>mother language</td>\n",
       "      <td>2.213384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sentence1              sentence2  difference\n",
       "40         operation type              user name    1.951066\n",
       "41              user name         operation type    1.951066\n",
       "42        mother language         operation type    1.980350\n",
       "43         operation type        mother language    1.980350\n",
       "44         operation type           manager name    2.036666\n",
       "45           manager name         operation type    2.036666\n",
       "46        mother language          vendor office    2.051085\n",
       "47          vendor office        mother language    2.051085\n",
       "48          office region           manager name    2.058947\n",
       "49           manager name          office region    2.058947\n",
       "50          mother tongue          office region    2.079474\n",
       "51          office region          mother tongue    2.079474\n",
       "52              user name  freelancer department    2.113164\n",
       "53  freelancer department              user name    2.113164\n",
       "54         operation type  freelancer department    2.117957\n",
       "55  freelancer department         operation type    2.117957\n",
       "56          vendor office   office business unit    2.121174\n",
       "57   office business unit          vendor office    2.121174\n",
       "58        mother language           manager name    2.213384\n",
       "59           manager name        mother language    2.213384"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differences.iloc[i * 20 : (i + 1) * 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3b5bc5c5-efc2-4432-afd9-0eeffef81327",
   "metadata": {},
   "outputs": [],
   "source": [
    "i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa5842-d8f3-4a4f-801d-cf74a4266b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
