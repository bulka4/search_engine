{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f3fb4c2-6cc7-48f1-95da-16865ee4db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.utils import pad_sequences\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5c1c7f-32ca-4db4-a20f-c24764eb1fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(string: str, \n",
    "               punctuations = r'''!()-[]{};:'\"\\,<>./?@#$%^&*_~''',\n",
    "               stop_words = stopwords.words('english'),\n",
    "               # porter = PorterStemmer()\n",
    "               wnl = WordNetLemmatizer()\n",
    "              ):\n",
    "    \"\"\"\n",
    "    A method to clean text. It removes punctuations, stop words, applies lemmatization.\n",
    "    \"\"\"\n",
    "    # Removing the punctuations\n",
    "    for x in string.lower(): \n",
    "        if x in punctuations: \n",
    "            string = string.replace(x, \"\") \n",
    "\n",
    "    # Converting the text to lower\n",
    "    string = string.lower()\n",
    "\n",
    "    # Removing stop words\n",
    "    string = ' '.join([word for word in string.split() if word not in stop_words])\n",
    "\n",
    "    # stemming/lemmatizing words. That means changing word to its basic format, for example\n",
    "    # words 'fishing', 'fished', 'fischer' will be changed into a word 'fisch'\n",
    "    # lemmatization should be better because stemming changes words too much, for example\n",
    "    # business is changed into busi\n",
    "    # string = ' '.join([porter.stem(word) for word in string.split()])\n",
    "    string = ' '.join([wnl.lemmatize(word, pos = \"v\") for word in string.split()])\n",
    "\n",
    "    # Cleaning the whitespaces\n",
    "    string = re.sub(r'\\s+', ' ', string).strip()\n",
    "\n",
    "    return string\n",
    "\n",
    "def create_training_data(tokenizer,\n",
    "                         sentences_file,\n",
    "                         # embed_matrix_file,\n",
    "                         model_folder,\n",
    "                         max_sen_len = None\n",
    "                        ):\n",
    "    \"\"\"\n",
    "    Creating a training and testing datasets self.x_train, self.x_test, self.y_train, self.y_test. This function\n",
    "    also creates and saves a tokenizer.\n",
    "    \"\"\"\n",
    "    sentences_tables = pd.read_excel(sentences_file).values\n",
    "    random.shuffle(sentences_tables)\n",
    "    clean_sentences = np.array([clean_text(sentence) for sentence in sentences_tables[:, 0]])\n",
    "\n",
    "    tokenizer.fit_on_texts(clean_sentences)\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(clean_sentences)\n",
    "    if max_sen_len == None:\n",
    "        max_sen_len = np.max([len(seq) for seq in sequences])\n",
    "    x = pad_sequences(sequences, maxlen = max_sen_len)\n",
    "\n",
    "    # embed_matrix = pd.read_csv(embed_matrix_file).values\n",
    "\n",
    "    x_train, x_test = train_test_split(x, test_size = 0.2)\n",
    "\n",
    "    with open(os.path.join(model_folder, 'tokenizer.json'), 'w') as file:\n",
    "        json.dump(tokenizer.to_json(), file)\n",
    "        \n",
    "    return x_train, x_test\n",
    "\n",
    "\n",
    "def get_coefs(word, *arr): \n",
    "    return word, list(np.asarray(arr, dtype='float'))\n",
    "\n",
    "\n",
    "def create_embedding_file(tokenizer,\n",
    "                          embed_file_src = r'model\\glove.840B.300d.txt', \n",
    "                          embed_file_trg = r'model\\model_embeddings.txt'\n",
    "                         ):\n",
    "    \"\"\"\n",
    "    This function will create an embedding file called embed_file_trg which will contain only those words \n",
    "    from embed_file_src which are present in the training dataset (tokenizer.word_index).\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings = dict(get_coefs(*o.split(\" \")) for o in open(embed_file_src, errors = 'ignore'))\n",
    "    with open(embed_file_trg, 'w') as file:\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            word_vector = embeddings[word]\n",
    "            line = ' '.join(np.concatenate([[word], word_vector]))\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "\n",
    "def create_embedding_matrix(tokenizer,\n",
    "                            model_folder,\n",
    "                            word_vec_dim,\n",
    "                            embed_file_path,\n",
    "                           ):\n",
    "    \"\"\"\n",
    "    A function to create an embedding matrix. This is a matrix where each row is a vector representing a word.\n",
    "    To create that matrix we use a word embedding file which path is equal to embedding_file_path.\n",
    "    embedding_matrix[row_number] is a vector representation for a word = list(tokenizer.word_index.keys())[row_number - 1]\n",
    "    First row of embedding_matrix are zeros. This matrix is needed to train a model.\n",
    "    \"\"\"\n",
    "    embeddings = dict(get_coefs(*o.split(\" \")) for o in open(embed_file_path, errors = 'ignore'))\n",
    "\n",
    "    # embedding_matrix[row_number] is a vector representation of a word = self.tokenizer.word_index.keys()[row_number - 1]\n",
    "    # first row in embedding_matrix is 0\n",
    "    embedding_matrix = np.zeros((len(tokenizer.word_counts) + 1, word_vec_dim))\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index > len(tokenizer.word_counts):\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                embedding_matrix[index] = embeddings[word]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    pd.DataFrame(embedding_matrix).to_csv(os.path.join(model_folder, 'embedding_matrix.csv'))\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a6c030-6b64-4d53-9cdf-18ae47d5b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "# max_sen_len = 20\n",
    "sentences_file = r'data\\sentences_tables.xlsx'\n",
    "embed_matrix_file = r'model\\embedding_matrix.csv'\n",
    "model_folder = 'model'\n",
    "word_vec_dim = 300\n",
    "embed_file_path = r'model\\model_embeddings.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa21b414-1a9d-4045-b551-9416b28cf16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = create_training_data(\n",
    "    tokenizer = tokenizer, \n",
    "    # max_sen_len = max_sen_len,\n",
    "    sentences_file = sentences_file,\n",
    "    # embed_matrix_file = embed_matrix_file,\n",
    "    model_folder = model_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "703325ad-5693-45fb-8ca5-0632a439fcfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0, 13, 15],\n",
       "       [ 2, 16,  4, ..., 21,  3,  7],\n",
       "       [ 0,  0,  0, ...,  0,  0,  4],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 18, 12, 24],\n",
       "       [ 0,  0,  0, ...,  8,  1, 10],\n",
       "       [ 0,  0,  0, ...,  5, 11,  6]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbd939a-fe1a-4b2d-9b3b-b46858c3282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_matrix = create_embedding_matrix(\n",
    "    tokenizer = tokenizer,\n",
    "    model_folder = model_folder,\n",
    "    word_vec_dim = word_vec_dim,\n",
    "    embed_file_path = embed_file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a69efdd-4542-4dfc-8cb3-d65237cdf61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [-0.50318 ,  0.27905 , -0.045497, ...,  0.4781  ,  0.13005 ,\n",
       "        -0.014399],\n",
       "       [-0.89423 ,  0.39636 ,  0.64359 , ..., -0.15076 ,  0.06987 ,\n",
       "         0.041258],\n",
       "       ...,\n",
       "       [ 0.37492 , -0.052425, -0.60094 , ..., -0.36104 , -0.065253,\n",
       "        -0.1206  ],\n",
       "       [ 0.012832,  0.22669 , -0.17511 , ...,  0.17134 ,  0.040047,\n",
       "        -0.37131 ],\n",
       "       [-0.39054 , -0.55117 , -0.073466, ...,  0.34569 ,  0.30918 ,\n",
       "        -0.32873 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b29fc-9891-4abb-8213-07ab482b117c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(embed_matrix):\n",
    "    if (row == np.zeros(300)).all():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8854e78-9e2f-4fde-973c-209d545335c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('employee', 1)\n",
      "('cost', 2)\n",
      "('user', 3)\n",
      "('office', 4)\n",
      "('business', 5)\n",
      "('unit', 6)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(tokenizer.word_index.items()):\n",
    "    print(item)\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "130632c9-bbf4-4a09-a7e1-e8c153935bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    def __init__(self,\n",
    "                 embedding_dim,\n",
    "                 lstm_out_size,\n",
    "                 batch_size,\n",
    "                 embed_matrix\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.lstm_out_size = lstm_out_size\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = layers.Embedding(\n",
    "            input_dim = embed_matrix.shape[0],\n",
    "            output_dim = embedding_dim,\n",
    "            embeddings_initializer = tf.keras.initializers.Constant(embed_matrix),\n",
    "            trainable = False\n",
    "        )\n",
    "        self.lstm = layers.LSTM(\n",
    "            units = self.lstm_out_size,\n",
    "            return_sequences = True,\n",
    "            return_state = True\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def call(self, x, state_h = None, state_c = None):\n",
    "        # x.shape = (batch_size, max_sen_len)\n",
    "        # x is a series of numbers which represent words\n",
    "        # state_h.shape = (batch_size, lstm_out_size)\n",
    "        \n",
    "        if state_h == None or state_c == None:\n",
    "            state_h, state_c = self.initialize_hidden_state()\n",
    "        \n",
    "        # make sure that the types are correct\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        state_h = tf.cast(state_h, tf.float32)\n",
    "        state_c = tf.cast(state_c, tf.float32)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        # x.shape after embedding = (batch_size, max_sen_len, embedding_dim)\n",
    "        # output.shape = (batch_size, max_sen_len, lstm_out_size)\n",
    "        # state_h.shape = (batch_size, lstm_out_size)\n",
    "        output, state_h, state_c = self.lstm(x, initial_state = [state_h, state_c])\n",
    "        return output, state_h, state_c\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        state_h = tf.zeros((self.batch_size, self.lstm_out_size))\n",
    "        state_c = tf.zeros((self.batch_size, self.lstm_out_size))\n",
    "        return state_h, state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07b1daa-cfc1-4cfe-85a6-a58ce5120f4f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(300, 40), dtype=float32, numpy=\n",
       " array([[-0.15583917,  0.2091645 , -0.12029857, ..., -0.1531712 ,\n",
       "         -0.2406035 , -0.09535917],\n",
       "        [ 0.0757622 , -0.10089249,  0.05824444, ...,  0.07151123,\n",
       "          0.11928213,  0.04373633],\n",
       "        [ 0.06349404, -0.09099954,  0.05075624, ...,  0.08390208,\n",
       "          0.08121173,  0.05794045],\n",
       "        ...,\n",
       "        [ 0.04093128, -0.04695676,  0.02919006, ...,  0.01054705,\n",
       "          0.08641959, -0.00131327],\n",
       "        [ 0.02300852, -0.02959532,  0.01737333, ...,  0.01783018,\n",
       "          0.03926679,  0.00983043],\n",
       "        [ 0.00269955, -0.00415654,  0.00224469, ...,  0.00463677,\n",
       "          0.00261603,  0.00341319]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 40), dtype=float32, numpy=\n",
       " array([[ 6.25123410e-03, -8.85592215e-03,  4.96598845e-03,\n",
       "          5.00731729e-03,  6.71169534e-03, -4.31275833e-03,\n",
       "         -1.14663516e-03,  3.36298090e-03,  8.90646945e-04,\n",
       "          4.72698221e-03,  1.57685904e-03, -1.36078731e-03,\n",
       "          1.39421085e-03,  8.55130609e-04,  4.23080084e-04,\n",
       "         -6.03405468e-04,  1.76902476e-03,  1.27408013e-03,\n",
       "          3.46744549e-03,  1.37365807e-03,  7.85011612e-03,\n",
       "          2.36197282e-02,  1.39031950e-02,  1.50097525e-02,\n",
       "          1.88236870e-02,  2.04707608e-02,  2.20136456e-02,\n",
       "          2.60661785e-02,  2.26066504e-02,  4.76549156e-02,\n",
       "          1.30445007e-02, -5.94842806e-03,  9.14702844e-03,\n",
       "          8.92328843e-03,  4.35651839e-03, -7.45385978e-03,\n",
       "          1.24803174e-03,  7.87613168e-03,  8.29633418e-03,\n",
       "          5.36314957e-03],\n",
       "        [-6.39664708e-03,  9.06192418e-03, -5.08150458e-03,\n",
       "         -5.12379454e-03, -6.86781947e-03,  4.41307947e-03,\n",
       "          1.17330754e-03, -3.44120874e-03, -9.11364739e-04,\n",
       "         -4.83693834e-03, -1.61353906e-03,  1.39244122e-03,\n",
       "         -1.42664218e-03, -8.75022204e-04, -4.32921544e-04,\n",
       "          6.17441547e-04, -1.81017478e-03, -1.30371714e-03,\n",
       "         -3.54810338e-03, -1.40561129e-03, -8.03272147e-03,\n",
       "         -2.41691582e-02, -1.42266043e-02, -1.53589016e-02,\n",
       "         -1.92615539e-02, -2.09469404e-02, -2.25257166e-02,\n",
       "         -2.66725160e-02, -2.31325142e-02, -4.87634391e-02,\n",
       "         -1.33479349e-02,  6.08679699e-03, -9.35980119e-03,\n",
       "         -9.13085695e-03, -4.45785746e-03,  7.62724737e-03,\n",
       "         -1.27706281e-03, -8.05934146e-03, -8.48931912e-03,\n",
       "         -5.48790442e-03],\n",
       "        [ 5.34006115e-03, -7.56509323e-03,  4.24215151e-03,\n",
       "          4.27745609e-03,  5.73340617e-03, -3.68413562e-03,\n",
       "         -9.79502918e-04,  2.87279650e-03,  7.60827272e-04,\n",
       "          4.03798232e-03,  1.34701782e-03, -1.16244040e-03,\n",
       "          1.19099219e-03,  7.30487751e-04,  3.61412414e-04,\n",
       "         -5.15453750e-04,  1.51117367e-03,  1.08837173e-03,\n",
       "          2.96203443e-03,  1.17343524e-03,  6.70589227e-03,\n",
       "          2.01769434e-02,  1.18766809e-02,  1.28219482e-02,\n",
       "          1.60799678e-02,  1.74869653e-02,  1.88049618e-02,\n",
       "          2.22668014e-02,  1.93115305e-02,  4.07087915e-02,\n",
       "          1.11431489e-02, -5.08139189e-03,  7.81376753e-03,\n",
       "          7.62264011e-03,  3.72151728e-03, -6.36739330e-03,\n",
       "          1.06612011e-03,  6.72811549e-03,  7.08707003e-03,\n",
       "          4.58142301e-03],\n",
       "        [ 5.08304825e-03, -7.20099080e-03,  4.03797952e-03,\n",
       "          4.07158537e-03,  5.45746181e-03, -3.50682088e-03,\n",
       "         -9.32360184e-04,  2.73453095e-03,  7.24209181e-04,\n",
       "          3.84363742e-03,  1.28218683e-03, -1.10649306e-03,\n",
       "          1.13367056e-03,  6.95329916e-04,  3.44017899e-04,\n",
       "         -4.90645354e-04,  1.43844204e-03,  1.03598915e-03,\n",
       "          2.81947386e-03,  1.11695868e-03,  6.38314243e-03,\n",
       "          1.92058422e-02,  1.13050649e-02,  1.22048371e-02,\n",
       "          1.53060509e-02,  1.66453309e-02,  1.78998932e-02,\n",
       "          2.11951174e-02,  1.83820799e-02,  3.87495048e-02,\n",
       "          1.06068375e-02, -4.83682798e-03,  7.43769668e-03,\n",
       "          7.25576794e-03,  3.54240322e-03, -6.06093556e-03,\n",
       "          1.01480843e-03,  6.40429603e-03,  6.74597453e-03,\n",
       "          4.36092261e-03],\n",
       "        [ 1.15452602e-03, -1.63557997e-03,  9.17156925e-04,\n",
       "          9.24789871e-04,  1.23956765e-03, -7.96513399e-04,\n",
       "         -2.11769409e-04,  6.21101179e-04,  1.64491532e-04,\n",
       "          8.73015437e-04,  2.91226461e-04, -2.51320656e-04,\n",
       "          2.57493579e-04,  1.57932111e-04,  7.81376875e-05,\n",
       "         -1.11441565e-04,  3.26717098e-04,  2.35306929e-04,\n",
       "          6.40394515e-04,  2.53697741e-04,  1.44981989e-03,\n",
       "          4.36227303e-03,  2.56774900e-03,  2.77211657e-03,\n",
       "          3.47650354e-03,  3.78069771e-03,  4.06564958e-03,\n",
       "          4.81410231e-03,  4.17517032e-03,  8.80127680e-03,\n",
       "          2.40915874e-03, -1.09860150e-03,  1.68934360e-03,\n",
       "          1.64802163e-03,  8.04595358e-04, -1.37663621e-03,\n",
       "          2.30496109e-04,  1.45462458e-03,  1.53223088e-03,\n",
       "          9.90507775e-04],\n",
       "        [-3.50832543e-03,  4.97013144e-03, -2.78701796e-03,\n",
       "         -2.81021278e-03, -3.76674603e-03,  2.42041145e-03,\n",
       "          6.43516018e-04, -1.88737630e-03, -4.99849964e-04,\n",
       "         -2.65288260e-03, -8.84966750e-04,  7.63702672e-04,\n",
       "         -7.82460673e-04, -4.79917449e-04, -2.37441520e-04,\n",
       "          3.38643964e-04, -9.92814195e-04, -7.15040835e-04,\n",
       "         -1.94600399e-03, -7.70926068e-04, -4.40565171e-03,\n",
       "         -1.32558923e-02, -7.80276814e-03, -8.42379220e-03,\n",
       "         -1.05642527e-02, -1.14886248e-02, -1.23545257e-02,\n",
       "         -1.46288928e-02, -1.26873320e-02, -2.67449506e-02,\n",
       "         -7.32085062e-03,  3.33838398e-03, -5.13350638e-03,\n",
       "         -5.00793895e-03, -2.44497065e-03,  4.18326445e-03,\n",
       "         -7.00421864e-04, -4.42025205e-03, -4.65607876e-03,\n",
       "         -3.00991349e-03],\n",
       "        [ 5.16731525e-03, -7.32036913e-03,  4.10492159e-03,\n",
       "          4.13908437e-03,  5.54793607e-03, -3.56495706e-03,\n",
       "         -9.47816938e-04,  2.77986424e-03,  7.36215210e-04,\n",
       "          3.90735734e-03,  1.30344299e-03, -1.12483650e-03,\n",
       "          1.15246465e-03,  7.06857129e-04,  3.49721056e-04,\n",
       "         -4.98779293e-04,  1.46228855e-03,  1.05316390e-03,\n",
       "          2.86621531e-03,  1.13547570e-03,  6.48896256e-03,\n",
       "          1.95242371e-02,  1.14924815e-02,  1.24071697e-02,\n",
       "          1.55597953e-02,  1.69212781e-02,  1.81966387e-02,\n",
       "          2.15464905e-02,  1.86868198e-02,  3.93918976e-02,\n",
       "          1.07826786e-02, -4.91701346e-03,  7.56099960e-03,\n",
       "          7.37605477e-03,  3.60112940e-03, -6.16141409e-03,\n",
       "          1.03163207e-03,  6.51046727e-03,  6.85780961e-03,\n",
       "          4.43321839e-03],\n",
       "        [ 7.86560681e-03, -1.11429514e-02,  6.24844758e-03,\n",
       "          6.30044984e-03,  8.44498165e-03, -5.42652188e-03,\n",
       "         -1.44275208e-03,  4.23146598e-03,  1.12065522e-03,\n",
       "          5.94771840e-03,  1.98408053e-03, -1.71220861e-03,\n",
       "          1.75426377e-03,  1.07596687e-03,  5.32339909e-04,\n",
       "         -7.59234070e-04,  2.22587283e-03,  1.60310953e-03,\n",
       "          4.36290819e-03,  1.72840327e-03,  9.87739768e-03,\n",
       "          2.97194887e-02,  1.74936764e-02,  1.88859999e-02,\n",
       "          2.36848779e-02,  2.57573053e-02,  2.76986398e-02,\n",
       "          3.27977315e-02,  2.84447856e-02,  5.99617325e-02,\n",
       "          1.64132249e-02, -7.48460134e-03,  1.15092350e-02,\n",
       "          1.12277148e-02,  5.48158307e-03, -9.37880855e-03,\n",
       "          1.57033419e-03,  9.91013180e-03,  1.04388511e-02,\n",
       "          6.74817525e-03],\n",
       "        [ 1.97604541e-02, -2.79939994e-02,  1.56977288e-02,\n",
       "          1.58283729e-02,  2.12159958e-02, -1.36328386e-02,\n",
       "         -3.62456939e-03,  1.06305452e-02,  2.81537813e-03,\n",
       "          1.49422195e-02,  4.98452783e-03, -4.30151448e-03,\n",
       "          4.40716790e-03,  2.70310929e-03,  1.33737666e-03,\n",
       "         -1.90739392e-03,  5.59197273e-03,  4.02742904e-03,\n",
       "          1.09607633e-02,  4.34219977e-03,  2.48145983e-02,\n",
       "          7.46631026e-02,  4.39486727e-02,  4.74465564e-02,\n",
       "          5.95025867e-02,  6.47090673e-02,  6.95862025e-02,\n",
       "          8.23964551e-02,  7.14607164e-02,  1.50639504e-01,\n",
       "          4.12342995e-02, -1.88032687e-02,  2.89142001e-02,\n",
       "          2.82069482e-02,  1.37711661e-02, -2.35620122e-02,\n",
       "          3.94508895e-03,  2.48968340e-02,  2.62251142e-02,\n",
       "          1.69531759e-02],\n",
       "        [ 7.99802970e-03, -1.13305505e-02,  6.35364419e-03,\n",
       "          6.40652189e-03,  8.58715829e-03, -5.51788136e-03,\n",
       "         -1.46704179e-03,  4.30270564e-03,  1.13952218e-03,\n",
       "          6.04785234e-03,  2.01748405e-03, -1.74103479e-03,\n",
       "          1.78379798e-03,  1.09408156e-03,  5.41302201e-04,\n",
       "         -7.72016239e-04,  2.26334692e-03,  1.63009891e-03,\n",
       "          4.43636067e-03,  1.75750209e-03,  1.00436900e-02,\n",
       "          3.02198362e-02,  1.77881923e-02,  1.92039590e-02,\n",
       "          2.40836274e-02,  2.61909459e-02,  2.81649642e-02,\n",
       "          3.33499052e-02,  2.89236717e-02,  6.09712265e-02,\n",
       "          1.66895520e-02, -7.61060929e-03,  1.17030004e-02,\n",
       "          1.14167407e-02,  5.57386922e-03, -9.53670684e-03,\n",
       "          1.59677176e-03,  1.00769745e-02,  1.06145954e-02,\n",
       "          6.86178543e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(40,), dtype=float32, numpy=\n",
       " array([ 0.22647852, -0.29777586,  0.17295852,  0.18814866,  0.13969946,\n",
       "        -0.10240686,  0.05799521,  0.16386303,  0.28073883,  0.17310983,\n",
       "         0.02701459, -0.02331287,  0.02388548,  0.01465001,  0.00724817,\n",
       "        -0.01033748,  0.03030676,  0.02182742,  0.05940393,  0.02353337,\n",
       "         0.4045195 ,  0.961509  ,  0.70492995,  0.78466487,  1.0684798 ,\n",
       "         1.5214539 ,  0.9106691 ,  1.2028753 ,  0.8107955 ,  2.4622512 ,\n",
       "         0.3070249 , -0.14263019,  0.21971658,  0.2153751 ,  0.08855505,\n",
       "        -0.16139503,  0.08530791,  0.19954212,  0.36770698,  0.11810707],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(embedding_dim = 300,\n",
    "                 lstm_out_size = 10,\n",
    "                 batch_size = 2,\n",
    "                 embed_matrix = embed_matrix\n",
    "                 )\n",
    "\n",
    "x = np.array([[1, 2], [1, 2]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    output, state_h, state_c = encoder(x)\n",
    "    \n",
    "variables = encoder.trainable_variables\n",
    "gradients = tape.gradient(output, variables)\n",
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e586409-6d87-463c-90dd-40135c565e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1 like in Jonathan Hui pdf\n",
    "class Bahdau_attention(layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = layers.Dense(units)\n",
    "        self.W2 = layers.Dense(units)\n",
    "        self.V = layers.Dense(1)\n",
    "        \n",
    "    def call(self, decoder_hidden, encoder_hidden):\n",
    "        # decoder_hidden.shape = (batch_size, hidden_size)\n",
    "        # decoder_hidden_time_axis.shape = (batch_size, 1, hidden_size)\n",
    "        decoder_hidden_time_axis = tf.expand_dims(decoder_hidden, 1)\n",
    "        \n",
    "        # encoder_hidden.shape = (batch_size, max_sen_len, hidden_size)\n",
    "        # argument for tanh shape = (batch_size, max_sen_len, hidden_size)\n",
    "        # score.shape = (batch_size, max_sen_len, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(decoder_hidden_time_axis) + self.W2(encoder_hidden)))\n",
    "        \n",
    "        # attention_weights.shape = (batch_size, max_sen_len, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis = 1)\n",
    "        \n",
    "        # context_vector.shape = (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * encoder_hidden\n",
    "        context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
    "        \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "398014c9-b9ab-4f29-84d1-7c96af06a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2, like in attention explanation pdf\n",
    "class Bahdau_attention(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(1)\n",
    "        \n",
    "    def call(self, decoder_state_h, encoder_states_h):\n",
    "        # decoder_state_h.shape = (batch_size, dec_state_size)\n",
    "        # encoder_states_h.shape = (batch_size, max_sen_len, enc_state_size)\n",
    "        \n",
    "        # make sure that the dtypes are correct\n",
    "        decoder_state_h = tf.cast(decoder_state_h, tf.float32)\n",
    "        encoder_states_h = tf.cast(encoder_states_h, tf.float32)\n",
    "        \n",
    "        # encoder_states_h_flattened.shape = (max_sen_len, enc_state_size)\n",
    "        encoder_states_h_flattened = tf.reshape(encoder_states_h, [-1, tf.shape(encoder_states_h)[2]])\n",
    "        batch_size, _, enc_state_size = tf.shape(encoder_states_h)\n",
    "        \n",
    "        max_sen_len = encoder_states_h.shape[1]\n",
    "        for i in range(batch_size):\n",
    "            attention_weights = tf.constant([])\n",
    "            for j in range(max_sen_len):\n",
    "                e = tf.constant([])\n",
    "                for k in range(max_sen_len):\n",
    "                    x = tf.concat([decoder_state_h[i], encoder_states_h_flattened[i + k]], 0)\n",
    "                    # x.shape = (dec_state_size + enc_state_size)\n",
    "                    x = tf.expand_dims(x, 0)\n",
    "                    # x.shape = (1, dec_state_size + enc_state_size)\n",
    "                    e = tf.experimental.numpy.append(e, tf.math.exp(self.dense(x)))\n",
    "\n",
    "                new_attention_weight = tf.math.divide(e[j], tf.math.reduce_sum(e))\n",
    "                attention_weights = tf.experimental.numpy.append(attention_weights, new_attention_weight)\n",
    "                \n",
    "            # context_vector.shape = (batch_size, enc_state_size)\n",
    "            new_context_vector_row = tf.reduce_sum([attention_weights[j] * encoder_states_h_flattened[i + j] for j in range(max_sen_len)], axis = 0)\n",
    "            new_context_vector_row = tf.expand_dims(new_context_vector_row, 0)\n",
    "            if i == 0:\n",
    "                context_vector = new_context_vector_row\n",
    "            else:\n",
    "                context_vector = tf.concat([context_vector, new_context_vector_row], axis = 0)\n",
    "        \n",
    "        return tf.cast(context_vector, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ec3a1b-a11a-496d-8cb8-95960056ab17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       " array([[9.536743e-07],\n",
       "        [0.000000e+00],\n",
       "        [9.536743e-07],\n",
       "        [8.584599e+00],\n",
       "        [8.584599e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = Bahdau_attention()\n",
    "decoder_state_h = tf.constant([[1,2,3], [4,5,6]])\n",
    "encoder_states_h = tf.constant([[[1,2], [4,5]], [[1,2], [4,5]]])\n",
    "encoder_states_h_flattened = tf.reshape(encoder_states_h, [-1, tf.shape(encoder_states_h)[2]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    context_vector = attention(decoder_state_h, encoder_states_h)\n",
    "    \n",
    "variables = attention.trainable_variables\n",
    "gradients = tape.gradient(context_vector, variables)\n",
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a40358e6-54e8-41a7-b551-131a2d5f8922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[4.872717 , 6.8218036],\n",
       "       [4.8727164, 6.821803 ]], dtype=float32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15a6c0cc-731a-475c-bc69-bea3475e4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, lstm_out_size, embed_matrix):\n",
    "        super().__init__()\n",
    "        self.lstm_out_size = lstm_out_size\n",
    "        self.embedding = layers.Embedding(\n",
    "            input_dim = embed_matrix.shape[0],\n",
    "            output_dim = embedding_dim,\n",
    "            embeddings_initializer = tf.keras.initializers.Constant(embed_matrix),\n",
    "            trainable = False\n",
    "        )\n",
    "        self.lstm = layers.LSTM(\n",
    "            units = self.lstm_out_size,\n",
    "            # return_sequences = True,\n",
    "            return_state = True\n",
    "        )\n",
    "        self.dense = layers.Dense(vocab_size)\n",
    "        self.attention = Bahdau_attention()\n",
    "        \n",
    "    def call(self, x, decoder_state_h, decoder_state_c, encoder_states_h):\n",
    "        # x.shape = (batch_size, 1)\n",
    "        # x is a single number for each batch representing a single word\n",
    "        # encoder_states_h.shape = (batch_size, max_sen_len, enc_state_size)\n",
    "        # decoder_state_h.shape = (batch_size, lstm_out_size)\n",
    "        \n",
    "        # make sure that the types are correct\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        decoder_state_h = tf.cast(decoder_state_h, tf.float32)\n",
    "        decoder_state_c = tf.cast(decoder_state_c, tf.float32)\n",
    "        encoder_states_h = tf.cast(encoder_states_h, tf.float32)\n",
    "        \n",
    "        # context_vector.shape = (batch_size, enc_state_size)\n",
    "        context_vector = self.attention(decoder_state_h, encoder_states_h)\n",
    "        # shape of output of embedding layer = (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        # x.shape after concatenation = (batch_size, 1, enc_state_size + embedding_dim)\n",
    "        # print('context_vector: ', tf.expand_dims(context_vector, 1))\n",
    "        # print('x: ', x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis = 2)\n",
    "        \n",
    "        output, state_h, state_c = self.lstm(x, initial_state = [decoder_state_h, decoder_state_c])\n",
    "        \n",
    "        # output.shape = (batch_size, vocab_size)\n",
    "        output = self.dense(output)\n",
    "        \n",
    "        return output, state_h, state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bfb23f3-bb93-4967-9b92-8bdf3247ab4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_size = 100, \n",
    "                  embedding_dim = 300, \n",
    "                  lstm_out_size = 20, \n",
    "                  embed_matrix = embed_matrix\n",
    "                 )\n",
    "\n",
    "x = tf.constant([[1], [2]])\n",
    "decoder_state_h = tf.constant([[i for i in range(20)], [i for i in range(20)]])\n",
    "decoder_state_c = tf.constant([[i for i in range(20)], [i for i in range(20)]])\n",
    "encoder_states_h = tf.constant([[[i for i in range(15)], [i for i in range(15)]], [[i for i in range(15)], [i for i in range(15)]]])\n",
    "\n",
    "output, state_h, state_c = decoder(x, decoder_state_h, decoder_state_c, encoder_states_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53ffc42e-fa8e-4ca6-956a-948ae38af438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inp, \n",
    "               targ, \n",
    "               # enc_state_h, \n",
    "               # enc_state_c, \n",
    "               batch_size, \n",
    "               encoder, \n",
    "               decoder, \n",
    "               loss_function, \n",
    "               optimizer):\n",
    "    # inp.shape = targ.shape (batch_size, max_sen_len)\n",
    "    # enc_state_h.shape = (batch_size, enc_state_size)\n",
    "    \n",
    "    # make sure that the types are correct\n",
    "    inp = tf.cast(inp, tf.float32)\n",
    "    targ = tf.cast(targ, tf.float32)\n",
    "    # enc_state_h = tf.cast(enc_state_h, tf.float32)\n",
    "    # enc_state_c = tf.cast(enc_state_c, tf.float32)\n",
    "    \n",
    "    batch_loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # enc_output.shape = (batch_size, max_sen_len, enc_state_size)\n",
    "        # enc_state_h.shape = (batch_size, state_size)\n",
    "        # enc_output, enc_state_h, enc_state_c = encoder(inp, enc_state_h, enc_state_c)\n",
    "        enc_output, enc_state_h, enc_state_c = encoder(inp)\n",
    "        dec_state_h = enc_state_h\n",
    "        dec_state_c = enc_state_c\n",
    "        \n",
    "        # dec_input.shape = (batch_size, 1)\n",
    "        dec_input = tf.expand_dims([0] * batch_size, 1)\n",
    "        \n",
    "        for t in range(targ.shape[1]):\n",
    "            prediction, dec_state_h, dec_state_c, = decoder(dec_input, dec_state_h, dec_state_c, enc_output)\n",
    "            # real value passed to loss_function needs to have shape (batch_size).\n",
    "            # It is a number representing a word from tokenizer.word_index. Real value = 0\n",
    "            # means that there was no word\n",
    "            batch_loss += loss_function(targ[:, t], prediction)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "            \n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(batch_loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16035f6f-2d3d-43bd-8f41-174494e45259",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction = 'none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype = loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a8ddff7-2151-45af-9547-df2a605e46cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([5.1293328e-02, 1.1920928e-07], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real = tf.expand_dims(x_train[:2, 0], 1)\n",
    "# pred = tf.expand_dims(x_train[:2, 0], 1)\n",
    "\n",
    "real = tf.constant([1, 0])\n",
    "pred = tf.constant([[0.05, 0.95], [1, 0]])\n",
    "\n",
    "real = tf.cast(real, tf.float32)\n",
    "pred = tf.cast(pred, tf.float32)\n",
    "\n",
    "loss_object(real, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "423aca49-8c11-4305-bb06-80e0091323dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 20\n",
    "embedding_dim = 300\n",
    "\n",
    "inp = tf.constant(x_train)\n",
    "targ = tf.constant(x_train)\n",
    "\n",
    "decoder = Decoder(vocab_size = len(tokenizer.word_index.keys()) + 1,\n",
    "                  embedding_dim = embedding_dim,\n",
    "                  lstm_out_size = 100,\n",
    "                  embed_matrix = embed_matrix\n",
    "                 )\n",
    "\n",
    "encoder = Encoder(embedding_dim = embedding_dim,\n",
    "                 lstm_out_size = 100,\n",
    "                 batch_size = batch_size,\n",
    "                 embed_matrix = embed_matrix\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48974688-4e2c-4b76-b5ea-b065ea4adc39",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number: 0, Loss: 2.302487850189209, Time per batch: 69.59460783004761\n",
      "Batch number: 1, Loss: 1.7420049905776978, Time per batch: 74.37116968631744\n",
      "Batch number: 2, Loss: 1.9498708248138428, Time per batch: 78.91649603843689\n",
      "Batch number: 3, Loss: 1.6511280536651611, Time per batch: 82.21579891443253\n",
      "Batch number: 4, Loss: 1.9404456615447998, Time per batch: 84.55168323516845\n",
      "Batch number: 5, Loss: 2.0121874809265137, Time per batch: 86.3509829044342\n",
      "Batch number: 6, Loss: 1.6229207515716553, Time per batch: 88.19867495128086\n",
      "Batch number: 7, Loss: 1.6128078699111938, Time per batch: 89.65208587050438\n",
      "Batch number: 8, Loss: 1.4715049266815186, Time per batch: 91.00284475750394\n",
      "Batch number: 9, Loss: 1.9867141246795654, Time per batch: 92.06984436511993\n",
      "Batch number: 10, Loss: 1.287858247756958, Time per batch: 92.94276629794727\n",
      "Batch number: 11, Loss: 1.6918995380401611, Time per batch: 93.77610743045807\n",
      "Batch number: 12, Loss: 1.3321683406829834, Time per batch: 94.74775103422311\n",
      "Batch number: 13, Loss: 1.8018014430999756, Time per batch: 95.78110906055996\n",
      "Batch number: 14, Loss: 1.4041756391525269, Time per batch: 96.52301646868388\n",
      "Batch number: 15, Loss: 1.5353020429611206, Time per batch: 97.25450958311558\n",
      "Batch number: 16, Loss: 1.3452186584472656, Time per batch: 97.83538585550644\n",
      "Batch number: 17, Loss: 1.715001106262207, Time per batch: 98.40661735004849\n",
      "Batch number: 18, Loss: 1.9415509700775146, Time per batch: 98.90940198145415\n",
      "Batch number: 19, Loss: 1.6435409784317017, Time per batch: 99.42126013040543\n",
      "Batch number: 20, Loss: 1.5353777408599854, Time per batch: 99.88509513082958\n",
      "Batch number: 21, Loss: 1.4326328039169312, Time per batch: 100.3137294812636\n",
      "Batch number: 22, Loss: 1.531768798828125, Time per batch: 100.70912552916485\n",
      "Batch number: 23, Loss: 1.344512701034546, Time per batch: 101.21826605002086\n",
      "Batch number: 24, Loss: 1.7320963144302368, Time per batch: 101.65905479431153\n",
      "Batch number: 25, Loss: 1.5570083856582642, Time per batch: 102.12426710128784\n",
      "Batch number: 26, Loss: 0.8224889039993286, Time per batch: 102.61712387756064\n",
      "Batch number: 27, Loss: 1.3115017414093018, Time per batch: 103.12160181999207\n",
      "Batch number: 28, Loss: 1.3274784088134766, Time per batch: 103.59310838271831\n",
      "Batch number: 29, Loss: 1.4241588115692139, Time per batch: 104.08322997887929\n",
      "Batch number: 30, Loss: 1.4582233428955078, Time per batch: 104.56866003621009\n",
      "Batch number: 31, Loss: 1.0828406810760498, Time per batch: 105.05873181670904\n",
      "\n",
      "Epoch: 0, Loss: 1.5797086954116821, Time per epoch: 3361.8794181346893\n",
      "Batch number: 0, Loss: 1.1820976734161377, Time per batch: 3482.1178176403046\n",
      "Batch number: 1, Loss: 1.0518999099731445, Time per batch: 1801.670930981636\n",
      "Batch number: 2, Loss: 1.196687936782837, Time per batch: 1241.9085208574932\n",
      "Batch number: 3, Loss: 1.1869679689407349, Time per batch: 962.2930220961571\n",
      "Batch number: 4, Loss: 1.3211767673492432, Time per batch: 794.6010790348053\n",
      "Batch number: 5, Loss: 1.220764398574829, Time per batch: 682.9525130192438\n",
      "Batch number: 6, Loss: 1.1945044994354248, Time per batch: 603.4341448034559\n",
      "Batch number: 7, Loss: 1.1429790258407593, Time per batch: 543.7877568006516\n",
      "Batch number: 8, Loss: 0.9614030718803406, Time per batch: 497.5767556826274\n",
      "Batch number: 9, Loss: 1.4231345653533936, Time per batch: 460.6247984409332\n",
      "Batch number: 10, Loss: 0.9504457712173462, Time per batch: 430.50722518834203\n",
      "Batch number: 11, Loss: 1.0655227899551392, Time per batch: 405.4809418121974\n",
      "Batch number: 12, Loss: 0.9690901041030884, Time per batch: 384.3556903875791\n",
      "Batch number: 13, Loss: 1.3903223276138306, Time per batch: 366.3577219418117\n",
      "Batch number: 14, Loss: 1.096468448638916, Time per batch: 350.8782010237376\n",
      "Batch number: 15, Loss: 1.2716881036758423, Time per batch: 337.45015174150467\n",
      "Batch number: 16, Loss: 0.8123672604560852, Time per batch: 325.7447500228882\n",
      "Batch number: 17, Loss: 1.2395882606506348, Time per batch: 315.40161436133917\n",
      "Batch number: 18, Loss: 1.4647899866104126, Time per batch: 306.26480342212477\n",
      "Batch number: 19, Loss: 1.379512071609497, Time per batch: 298.1058521747589\n",
      "Batch number: 20, Loss: 1.1494008302688599, Time per batch: 290.96263305346173\n",
      "Batch number: 21, Loss: 1.1048921346664429, Time per batch: 284.5198623158715\n",
      "Batch number: 22, Loss: 1.0852184295654297, Time per batch: 278.6798801422119\n",
      "Batch number: 23, Loss: 1.1562918424606323, Time per batch: 273.44561553994816\n",
      "Batch number: 24, Loss: 1.58311128616333, Time per batch: 268.70577132225037\n",
      "Batch number: 25, Loss: 1.3183162212371826, Time per batch: 264.31331885777985\n",
      "Batch number: 26, Loss: 0.7639741897583008, Time per batch: 260.38208130553915\n",
      "Batch number: 27, Loss: 1.1125175952911377, Time per batch: 256.7933013354029\n",
      "Batch number: 28, Loss: 1.06074059009552, Time per batch: 253.47513128971232\n",
      "Batch number: 29, Loss: 1.328934669494629, Time per batch: 250.44140136241913\n",
      "Batch number: 30, Loss: 1.3542927503585815, Time per batch: 247.65011760496324\n",
      "Batch number: 31, Loss: 0.9731804132461548, Time per batch: 245.08510947972536\n",
      "\n",
      "Epoch: 1, Loss: 1.172258973121643, Time per epoch: 3921.361751675606\n",
      "Batch number: 0, Loss: 1.142012357711792, Time per batch: 8009.106654167175\n",
      "Batch number: 1, Loss: 0.9650480151176453, Time per batch: 4089.1422164440155\n",
      "Batch number: 2, Loss: 1.0285685062408447, Time per batch: 2782.6856306393943\n",
      "Batch number: 3, Loss: 1.0342649221420288, Time per batch: 2129.9328926205635\n",
      "Batch number: 4, Loss: 1.1597117185592651, Time per batch: 1738.3898250579834\n",
      "Batch number: 5, Loss: 1.1310431957244873, Time per batch: 1477.7359210252762\n",
      "Batch number: 6, Loss: 1.1417161226272583, Time per batch: 1291.7440694400243\n",
      "Batch number: 7, Loss: 1.0063598155975342, Time per batch: 1152.4458330869675\n",
      "Batch number: 8, Loss: 0.8333374261856079, Time per batch: 1044.337335480584\n",
      "Batch number: 9, Loss: 1.4564595222473145, Time per batch: 958.1065085411071\n",
      "Batch number: 10, Loss: 0.8696081042289734, Time per batch: 887.6583279479634\n",
      "Batch number: 11, Loss: 1.0975253582000732, Time per batch: 829.0598805745443\n",
      "Batch number: 12, Loss: 0.8352466821670532, Time per batch: 779.5849955632136\n",
      "Batch number: 13, Loss: 1.3208338022232056, Time per batch: 737.3176536900656\n",
      "Batch number: 14, Loss: 0.8931307792663574, Time per batch: 700.793967072169\n",
      "Batch number: 15, Loss: 1.1219770908355713, Time per batch: 668.9017360210419\n",
      "Batch number: 16, Loss: 1.0496089458465576, Time per batch: 640.8527662052828\n",
      "Batch number: 17, Loss: 1.1668179035186768, Time per batch: 616.0263052384058\n",
      "Batch number: 18, Loss: 1.3015937805175781, Time per batch: 593.8881087177679\n",
      "Batch number: 19, Loss: 1.289557695388794, Time per batch: 574.0362953186035\n",
      "Batch number: 20, Loss: 1.1717429161071777, Time per batch: 556.1489639509292\n",
      "Batch number: 21, Loss: 0.9604423642158508, Time per batch: 539.9703675941987\n",
      "Batch number: 22, Loss: 1.254436731338501, Time per batch: 525.3209197002908\n",
      "Batch number: 23, Loss: 1.3215343952178955, Time per batch: 511.93352766831714\n",
      "Batch number: 24, Loss: 1.4327884912490845, Time per batch: 499.6767566204071\n",
      "Batch number: 25, Loss: 1.0113447904586792, Time per batch: 488.43936789035797\n",
      "Batch number: 26, Loss: 0.8701709508895874, Time per batch: 478.10196188644125\n",
      "Batch number: 27, Loss: 1.3079050779342651, Time per batch: 468.55937207596645\n",
      "Batch number: 28, Loss: 1.2465441226959229, Time per batch: 459.73684180193936\n",
      "Batch number: 29, Loss: 1.466589093208313, Time per batch: 451.5444045782089\n",
      "Batch number: 30, Loss: 1.2770124673843384, Time per batch: 443.95461425473616\n",
      "Batch number: 31, Loss: 1.1369082927703857, Time per batch: 436.89274041354656\n",
      "\n",
      "Epoch: 2, Loss: 1.1344324350357056, Time per epoch: 4660.18923107783\n",
      "Batch number: 0, Loss: 1.2414644956588745, Time per batch: 14200.50833773613\n",
      "Batch number: 1, Loss: 0.9984668493270874, Time per batch: 7210.33203959465\n",
      "Batch number: 2, Loss: 1.381127953529358, Time per batch: 4881.110113461812\n",
      "Batch number: 3, Loss: 1.320904016494751, Time per batch: 3717.035585641861\n",
      "Batch number: 4, Loss: 1.2674829959869385, Time per batch: 3018.763019800186\n",
      "Batch number: 5, Loss: 1.3202472925186157, Time per batch: 2553.6852515538535\n",
      "Batch number: 6, Loss: 1.2581422328948975, Time per batch: 2221.684455394745\n",
      "Batch number: 7, Loss: 1.2480347156524658, Time per batch: 1972.986110240221\n",
      "Batch number: 8, Loss: 1.04167640209198, Time per batch: 1779.6996099948883\n",
      "Batch number: 9, Loss: 1.0720252990722656, Time per batch: 1625.197222828865\n",
      "Batch number: 10, Loss: 0.9763080477714539, Time per batch: 1498.905470089479\n",
      "Batch number: 11, Loss: 1.0930840969085693, Time per batch: 1393.8513666788738\n",
      "Batch number: 12, Loss: 0.8518762588500977, Time per batch: 1305.0939438343048\n",
      "Batch number: 13, Loss: 1.1198776960372925, Time per batch: 1229.0801770516805\n",
      "Batch number: 14, Loss: 0.9475887417793274, Time per batch: 1163.3148875236511\n",
      "Batch number: 15, Loss: 1.0720196962356567, Time per batch: 1105.8872633576393\n",
      "Batch number: 16, Loss: 1.1526472568511963, Time per batch: 1055.2575132285847\n",
      "Batch number: 17, Loss: 1.2921664714813232, Time per batch: 1010.4251128700045\n",
      "Batch number: 18, Loss: 1.330452799797058, Time per batch: 970.3501647020641\n",
      "Batch number: 19, Loss: 1.081591248512268, Time per batch: 934.4122772574425\n",
      "Batch number: 20, Loss: 1.282594919204712, Time per batch: 901.9761699154263\n",
      "Batch number: 21, Loss: 1.2269917726516724, Time per batch: 872.5615885366093\n",
      "Batch number: 22, Loss: 1.1581640243530273, Time per batch: 845.8394421287205\n",
      "Batch number: 23, Loss: 1.1390208005905151, Time per batch: 821.3759663701057\n",
      "Batch number: 24, Loss: 1.2780381441116333, Time per batch: 798.9489542293549\n",
      "Batch number: 25, Loss: 1.171319842338562, Time per batch: 778.3077522424551\n",
      "Batch number: 26, Loss: 0.8710159063339233, Time per batch: 759.2913756282242\n",
      "Batch number: 27, Loss: 1.3772531747817993, Time per batch: 741.6873865042414\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6732/2614338014.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m                                \u001b[0mdecoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                                \u001b[0mloss_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                                \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m                               )\n\u001b[0;32m     16\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6732/1699318176.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(inp, targ, batch_size, encoder, decoder, loss_function, optimizer)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1088\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_StridedSliceGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ellipsis_mask\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"new_axis_mask\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m       shrink_axis_mask=op.get_attr(\"shrink_axis_mask\")), None, None, None\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice_grad\u001b[1;34m(shape, begin, end, strides, dy, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  10860\u001b[0m         \u001b[1;34m\"begin_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ellipsis_mask\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10861\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"new_axis_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shrink_axis_mask\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10862\u001b[1;33m         shrink_axis_mask)\n\u001b[0m\u001b[0;32m  10863\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10864\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    stime = time.time()\n",
    "    total_loss = 0\n",
    "    for batch_number in range(len(inp) // batch_size):\n",
    "        inp_batch = inp[batch_number * batch_size : (batch_number + 1) * batch_size, :]\n",
    "        targ_batch = targ[batch_number * batch_size : (batch_number + 1) * batch_size, :]\n",
    "        \n",
    "        batch_loss = train_step(inp = inp_batch, \n",
    "                               targ = targ_batch,\n",
    "                               batch_size = batch_size,\n",
    "                               encoder = encoder, \n",
    "                               decoder = decoder, \n",
    "                               loss_function = loss_function, \n",
    "                               optimizer = optimizer\n",
    "                              )\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        print(f'Batch number: {batch_number}, Loss: {batch_loss / batch_size}, Time per batch: {(time.time() - stime) / (batch_number + 1)}')\n",
    "        \n",
    "    print(f'Epoch: {epoch + 1}, Loss: {total_loss / ((batch_number + 1) * batch_size)}, Time per epoch: {time.time() - stime}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e01287fe-3046-471e-8839-c24375ec2207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/encoder\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/encoder\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000029630F42B08> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "encoder.save('model/encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f96b89c0-8f1e-48f0-8757-63827446b636",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in user code:\n\n    File \"c:\\python\\python37\\lib\\site-packages\\keras\\saving\\saving_utils.py\", line 125, in _wrapped_model  *\n        outputs = model(*args, **kwargs)\n    File \"c:\\python\\python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling layer \"decoder_1\" (type Decoder).\n    \n    in user code:\n    \n        File \"C:\\Users\\mbulk\\AppData\\Local\\Temp/ipykernel_6732/1709298366.py\", line 32, in call  *\n            context_vector = self.attention(decoder_state_h, encoder_states_h)\n        File \"c:\\python\\python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        OperatorNotAllowedInGraphError: Exception encountered when calling layer \"bahdau_attention_2\" (type Bahdau_attention).\n        \n        in user code:\n        \n            File \"C:\\Users\\mbulk\\AppData\\Local\\Temp/ipykernel_6732/3099152875.py\", line 17, in call  *\n                batch_size, _, enc_state_size = tf.shape(encoder_states_h)\n        \n            OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n        \n        \n        Call arguments received:\n           decoder_state_h=tf.Tensor(shape=(None, 100), dtype=float32)\n           encoder_states_h=tf.Tensor(shape=(None, 13, 100), dtype=float32)\n    \n    \n    Call arguments received:\n       x=tf.Tensor(shape=(None, 1), dtype=int32)\n       decoder_state_h=tf.Tensor(shape=(None, 100), dtype=float32)\n       decoder_state_c=tf.Tensor(shape=(None, 100), dtype=float32)\n       encoder_states_h=tf.Tensor(shape=(None, 13, 100), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6732/3718568018.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model/decoder'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    File \"c:\\python\\python37\\lib\\site-packages\\keras\\saving\\saving_utils.py\", line 125, in _wrapped_model  *\n        outputs = model(*args, **kwargs)\n    File \"c:\\python\\python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling layer \"decoder_1\" (type Decoder).\n    \n    in user code:\n    \n        File \"C:\\Users\\mbulk\\AppData\\Local\\Temp/ipykernel_6732/1709298366.py\", line 32, in call  *\n            context_vector = self.attention(decoder_state_h, encoder_states_h)\n        File \"c:\\python\\python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        OperatorNotAllowedInGraphError: Exception encountered when calling layer \"bahdau_attention_2\" (type Bahdau_attention).\n        \n        in user code:\n        \n            File \"C:\\Users\\mbulk\\AppData\\Local\\Temp/ipykernel_6732/3099152875.py\", line 17, in call  *\n                batch_size, _, enc_state_size = tf.shape(encoder_states_h)\n        \n            OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n        \n        \n        Call arguments received:\n           decoder_state_h=tf.Tensor(shape=(None, 100), dtype=float32)\n           encoder_states_h=tf.Tensor(shape=(None, 13, 100), dtype=float32)\n    \n    \n    Call arguments received:\n       x=tf.Tensor(shape=(None, 1), dtype=int32)\n       decoder_state_h=tf.Tensor(shape=(None, 100), dtype=float32)\n       decoder_state_c=tf.Tensor(shape=(None, 100), dtype=float32)\n       encoder_states_h=tf.Tensor(shape=(None, 13, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "decoder.save('model/decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16de5c38-a405-44e8-ab4b-aa722980ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.save_weights('model/decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a728ecf-d048-41f6-8b72-b4ffe7ea68b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564852cf-572d-4a31-9ffd-f480e106454d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1babf107-ce99-44d3-9207-feea1ca3a5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a678df9-3be9-448c-bdff-5ef63c7f8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = 'hierarchy region business unit'\n",
    "sentence2 = 'hierarchy region'\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences([sentence1, sentence2])\n",
    "x = pad_sequences(sequences, maxlen = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80d62a0b-77d9-4074-a5bf-acc152f27562",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20 - x.shape[0]):\n",
    "    x = np.concatenate((x, np.zeros((1, 20))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abc828e0-3b3b-4ab6-a0c2-c7f20df58db5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0., 13., 15.,  5.,  6.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0., 13., 15.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ffb6d2c-b344-4cd9-80a8-40a72613ea02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(20, 20, 100), dtype=float32, numpy=\n",
       " array([[[-0.00200214, -0.00728252,  0.00461565, ..., -0.00156335,\n",
       "           0.00536895, -0.00102761],\n",
       "         [-0.00376189, -0.01406969,  0.00852322, ..., -0.00338283,\n",
       "           0.01094341, -0.00149374],\n",
       "         [-0.00536775, -0.02020802,  0.01205186, ..., -0.00521175,\n",
       "           0.01671277, -0.00152385],\n",
       "         ...,\n",
       "         [-0.5295285 , -0.21979973,  0.5503003 , ...,  0.03106904,\n",
       "           0.24107699, -0.02291696],\n",
       "         [-0.7674839 , -0.49447724,  0.6714796 , ..., -0.01835466,\n",
       "           0.57227296, -0.02126507],\n",
       "         [-0.82453334, -0.65076756,  0.719726  , ...,  0.03668921,\n",
       "           0.65055186, -0.06996637]],\n",
       " \n",
       "        [[-0.00200214, -0.00728252,  0.00461565, ..., -0.00156335,\n",
       "           0.00536895, -0.00102761],\n",
       "         [-0.00376189, -0.01406969,  0.00852322, ..., -0.00338283,\n",
       "           0.01094341, -0.00149374],\n",
       "         [-0.00536775, -0.02020802,  0.01205186, ..., -0.00521175,\n",
       "           0.01671277, -0.00152385],\n",
       "         ...,\n",
       "         [-0.04916742, -0.05725222,  0.08820748, ..., -0.01597076,\n",
       "           0.1287282 ,  0.01421669],\n",
       "         [-0.4745788 , -0.16935304,  0.47248846, ..., -0.03609582,\n",
       "           0.21732019, -0.0452124 ],\n",
       "         [-0.53876215, -0.22294153,  0.56159866, ...,  0.02996359,\n",
       "           0.26106238, -0.02076698]],\n",
       " \n",
       "        [[-0.00200214, -0.00728252,  0.00461565, ..., -0.00156335,\n",
       "           0.00536895, -0.00102761],\n",
       "         [-0.00376189, -0.01406969,  0.00852322, ..., -0.00338283,\n",
       "           0.01094341, -0.00149374],\n",
       "         [-0.00536775, -0.02020802,  0.01205186, ..., -0.00521175,\n",
       "           0.01671277, -0.00152385],\n",
       "         ...,\n",
       "         [-0.04916742, -0.05725222,  0.08820748, ..., -0.01597076,\n",
       "           0.1287282 ,  0.01421669],\n",
       "         [-0.05446996, -0.05849396,  0.09591879, ..., -0.01626944,\n",
       "           0.13858907,  0.01542302],\n",
       "         [-0.06014477, -0.05976397,  0.1040401 , ..., -0.01657969,\n",
       "           0.1488874 ,  0.016623  ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.00200214, -0.00728252,  0.00461565, ..., -0.00156335,\n",
       "           0.00536895, -0.00102761],\n",
       "         [-0.00376189, -0.01406969,  0.00852322, ..., -0.00338283,\n",
       "           0.01094341, -0.00149374],\n",
       "         [-0.00536775, -0.02020802,  0.01205186, ..., -0.00521175,\n",
       "           0.01671277, -0.00152385],\n",
       "         ...,\n",
       "         [-0.04916742, -0.05725222,  0.08820748, ..., -0.01597076,\n",
       "           0.1287282 ,  0.01421669],\n",
       "         [-0.05446996, -0.05849396,  0.09591879, ..., -0.01626944,\n",
       "           0.13858907,  0.01542302],\n",
       "         [-0.06014477, -0.05976397,  0.1040401 , ..., -0.01657969,\n",
       "           0.1488874 ,  0.016623  ]],\n",
       " \n",
       "        [[-0.00200214, -0.00728252,  0.00461565, ..., -0.00156335,\n",
       "           0.00536895, -0.00102761],\n",
       "         [-0.00376189, -0.01406969,  0.00852322, ..., -0.00338283,\n",
       "           0.01094341, -0.00149374],\n",
       "         [-0.00536775, -0.02020802,  0.01205186, ..., -0.00521175,\n",
       "           0.01671277, -0.00152385],\n",
       "         ...,\n",
       "         [-0.04916742, -0.05725222,  0.08820748, ..., -0.01597077,\n",
       "           0.1287282 ,  0.01421669],\n",
       "         [-0.05446995, -0.05849396,  0.09591879, ..., -0.01626945,\n",
       "           0.13858904,  0.01542302],\n",
       "         [-0.06014475, -0.05976397,  0.1040401 , ..., -0.0165797 ,\n",
       "           0.1488874 ,  0.016623  ]],\n",
       " \n",
       "        [[-0.00200214, -0.00728252,  0.00461565, ..., -0.00156335,\n",
       "           0.00536895, -0.00102761],\n",
       "         [-0.00376189, -0.01406969,  0.00852322, ..., -0.00338283,\n",
       "           0.01094341, -0.00149374],\n",
       "         [-0.00536775, -0.02020802,  0.01205186, ..., -0.00521175,\n",
       "           0.01671277, -0.00152385],\n",
       "         ...,\n",
       "         [-0.04916742, -0.05725222,  0.08820748, ..., -0.01597077,\n",
       "           0.1287282 ,  0.01421669],\n",
       "         [-0.05446995, -0.05849396,  0.09591879, ..., -0.01626945,\n",
       "           0.13858904,  0.01542302],\n",
       "         [-0.06014475, -0.05976397,  0.1040401 , ..., -0.0165797 ,\n",
       "           0.1488874 ,  0.016623  ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 100), dtype=float32, numpy=\n",
       " array([[-0.82453334, -0.65076756,  0.719726  , ...,  0.03668921,\n",
       "          0.65055186, -0.06996637],\n",
       "        [-0.53876215, -0.22294153,  0.56159866, ...,  0.02996359,\n",
       "          0.26106238, -0.02076698],\n",
       "        [-0.06014477, -0.05976397,  0.1040401 , ..., -0.01657969,\n",
       "          0.1488874 ,  0.016623  ],\n",
       "        ...,\n",
       "        [-0.06014477, -0.05976397,  0.1040401 , ..., -0.01657969,\n",
       "          0.1488874 ,  0.016623  ],\n",
       "        [-0.06014475, -0.05976397,  0.1040401 , ..., -0.0165797 ,\n",
       "          0.1488874 ,  0.016623  ],\n",
       "        [-0.06014475, -0.05976397,  0.1040401 , ..., -0.0165797 ,\n",
       "          0.1488874 ,  0.016623  ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 100), dtype=float32, numpy=\n",
       " array([[-1.899285  , -1.2655983 ,  2.0156975 , ...,  0.15124242,\n",
       "          1.6290064 , -0.18947455],\n",
       "        [-0.9315984 , -0.405277  ,  0.982164  , ...,  0.07860176,\n",
       "          0.52806044, -0.03951072],\n",
       "        [-0.11419453, -0.11446515,  0.20176119, ..., -0.03626619,\n",
       "          0.2822519 ,  0.03376711],\n",
       "        ...,\n",
       "        [-0.11419453, -0.11446515,  0.20176119, ..., -0.03626619,\n",
       "          0.2822519 ,  0.03376711],\n",
       "        [-0.1141945 , -0.11446516,  0.20176119, ..., -0.03626619,\n",
       "          0.2822519 ,  0.03376712],\n",
       "        [-0.1141945 , -0.11446516,  0.20176119, ..., -0.03626619,\n",
       "          0.2822519 ,  0.03376712]], dtype=float32)>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80260e5-6b68-4a3c-948f-da685692c7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
